{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/varsha/.local/lib/python3.8/site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.14.5; python_version >= \"3.7\" in /home/varsha/.local/lib/python3.8/site-packages (from opencv-python) (1.19.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'02691156': 'airplane', '02933112': 'cabinet', '02958343': 'car', '03001627': 'chair', '03636649': 'lamp', '04256520': 'sofa', '04379243': 'table', '04530566': 'watercraft'}\n"
     ]
    }
   ],
   "source": [
    "from src.data.shapenet import ShapeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'02691156': 'airplane',\n",
       " '02933112': 'cabinet',\n",
       " '02958343': 'car',\n",
       " '03001627': 'chair',\n",
       " '03636649': 'lamp',\n",
       " '04256520': 'sofa',\n",
       " '04379243': 'table',\n",
       " '04530566': 'watercraft'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ShapeNet.class_name_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "dataset = ShapeNet('overfit','02691156' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "(1024, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import torch\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "\n",
    "data_pcl = torch.reshape(data['pcl'], ( 1024, 3)).numpy()\n",
    "print(data_pcl.shape)\n",
    "\n",
    "pcd.points = o3d.utility.Vector3dVector(data_pcl)\n",
    "o3d.io.write_point_cloud(\"./data.ply\", pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f7110ecac70994a83820d8f180caa23a'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f37efba4430>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensor_image = data['img_rgb']\n",
    "print(tensor_image.shape)\n",
    "plt.imshow(  tensor_image.permute(1, 2, 0)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f37efacdf40>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAqmElEQVR4nO2da4xs2VXff6veXVV9+3X79n1M+94748HB8GE8Y9mWYhzyMvYoyWAUOfYHGAjKgGRHIBEFA1FihS9AsBGIxNEgLMYIPDjh4ZFFAo5DYiRi8IwZxmMP87xzZ27f28/qqq73c+fDOfvUqepT3dVdVV3d96yfVKqqfV676pz9P2utvc7eYoxBUZTwEpl2BRRFmS4qAooSclQEFCXkqAgoSshREVCUkKMioCghZ2IiICIfEJEXReQVEfnEpI6jKMpoyCTyBEQkCrwE/GPgFvB14KPGmG+P/WCKoozEpCyBdwGvGGNeM8Y0gCeBRyZ0LEVRRiA2of1eAd70fb8FvHvQyiKiaYuKMnm2jTHL/YWTEoFDEZHHgMemdXxFCSE3gwonJQJrwKrv+z1umYcx5nHgcVBLQFGmyaRiAl8H7heR6yKSAD4CPDWhYymKMgITsQSMMS0R+TjwJ0AU+Kwx5luTOJaiKKMxkS7CI1dC3QFFOQmeMca8s79QMwYVJeSoCChKyFERUJSQoyKgKCFHRUBRQo6KgKKEHBUBRQk5KgKKEnJUBBQl5KgIKErIURFQlJCjIqAoIUdFQFFCjoqAooQcFQFFCTnHFgERWRWRPxORb4vIt0TkJ9zyT4rImog8674eHl91FUUZN6OMLNQCfsoY8w0RmQWeEZEvu8t+xRjzy6NXT1GUSXNsETDG3AHuuJ+LIvICzlDjiqKcIcYSExCRa8A7gL90iz4uIs+JyGdFZGEcx1AUZTKMLAIikgV+H/hJY8we8BngPuABHEvhUwO2e0xEnhaRp0etg6Iox2ekgUZFJA58CfgTY8ynA5ZfA75kjPnuQ/ajA40qyuQZ70CjIiLAbwIv+AVARC75VvsQ8Pxxj6EoyuQZpXfg7wI/CHxTRJ51y34W+KiIPAAY4HXgx0Y4hqIoE0bnHVCU8KDzDiiKsh8VAUUJOSoCihJyVAQUJeSoCChKyFERUJSQoyKgKCFHRUBRQo6KgKKEHBUBRQk5KgKKEnJUBBQl5KgIKErIURFQlJCjIqAoIUdFQFFCzigjCwEgIq8DRaANtIwx7xSRReD3gGs4owt92BizO+qxFEUZP+OyBP6+MeYB36glnwC+Yoy5H/iK+11RlFPIpNyBR4An3M9PAN8/oeMoijIi4xABA/ypiDwjIo+5ZSvuDEUA68BK/0Y674CinA5GjgkA7zXGrInIBeDLIvK3/oXGGBM0kKgx5nHgcdCBRhVlmoxsCRhj1tz3TeAPgXcBG3b+Afd9c9TjKIoyGUYSARHJuDMSIyIZ4P04k408BTzqrvYo8MVRjqMoyuQY1R1YAf7QmYyIGPC7xpj/KSJfB74gIj8K3AQ+POJxFEWZEDr5iKKEB518RFGU/agIKErIURFQlJCjIqAoIUdFQFFCjoqAooQcFQFFCTkqAooSclQEFCXkqAgoSshREVCUkKMioCghR0VAUUKOioCihBwVAUUJOcceVERE3oYzt4DlXuDfA/PAvwK23PKfNcb88XGPoyjKZBnLoCIiEgXWgHcDPwKUjDG/fITtdVAR5UQREeLxODMzMwCUy2VardaUazVxAgcVGcdowwD/EHjVGHPTHWpMUU4lsViM2dlZlpYWmZ+fJ5VKYQzkcjvcvn2HYrFIp9OZdjVPlHGJwEeAz/u+f1xEfgh4GvgpnYJMOQ0kEnFWV1e5dOkS0WjUKxcRLly4wNzcHJubW2xsbFCpVDgNQ++dBCMHBkUkAfwz4L+5RZ8B7gMeAO4Anxqw3amafMSah4lEYtpVUSZEq9WmUNij2Wx6ZX7DNZlMsrp6D9/5nX+Hy5cvh+ZaGDkmICKPAB8zxrw/YNk14EvGmO8+ZB9TkVzb8LPZLAsLCywszGOM4c6ddba2tnouFuVk8LuTk7gTx2JRLl68yOrqKolEHNjvvooInU6HQmGP27dvs7u7e7fECyYWE/goPldARC75piD7EM48BKeKWCxGJpNhcXGR+fk50uk0sVgMEcEYw1vfeh/nzy+xubnF1tYW7XZ72lXeRzKZJJlMUi6XT2X9/ESjURKJOOl0htnZWSIRod1u0253aLVadDptjDFks7PMzztC3Gq1KJfLFAoFGo0GtVrN+52jiEOr1WZjY5NoNMrly5eJx+P0x7GMMUQiETduMMfm5iZra7cplUp3ZbxgJEvAnXDkDeBeY0zBLfttHFfA4ExL/mM+URi0nxO1BK5fv86lSxcDLwCLMQZjDLu7u6yt3aZQKJyaxpZMJnnooQdJp9M8//zzrK9vTLtKgYgImUyGlZUVlpYWyWazZLNZ2u22d2e1/3M0GuXq1WtcuXKFSCSCMYZ2u029XqdUKnHjxg1eeuklyuUSzWaLVst5OWLSotNx1u90OkOJRDwe5/LlS1y6dIlEIhF4HYgIIkIkEqFQKLC+vs7m5haNRmPs/9UJMX5LwBhTBpb6yn5wlH2eBJVKZWDjd7RLvAtgcXGRc+fOkcvlTs3dIBaLMTMzQywWY25uno2NzVMZxEqn01y/fp2LF1dIJhNuME6IRqNEIkKj0fTEIBqNUqvV2NvbIx6PE4lEPHft/PnzLCwsEI/HKJVK3m/tdDo0m84+rLWQz+fJ5Xap1WreHT0ej3uCYWk2m9y+fQdjjOf/B1kE9n1ubo5z586xvLzM66/fZG9v79TcFEZlXL0DZ4rd3V1KpRJzc/OA6Tv5vReCvRBt9Hh7e8eLHk/rImi321QqFZLJJOfOzRKLxU5d/CIej7O8vMzy8nlmZmbodJy7v1+r4vG41/grlQqvv36D27fXSKVSpNNpkskk8XiCWCxGq9Wk2WwiIiQSCeLxGCA9DdVaDvl8gbW1Nba2tkilUqyurlIul9ne3qZWq3ki3mw2WV/fQEQGWgTGGDqdDpFIhEgkwvLyMul0mlu3brG+vkGj0TiVAnwUQikCjUaDjY0Nstkssdhwf4GIkEqluHLlMouLC2xtbbG5uUW1Wj1xy8D6y7FYjGQyRTKZPFUiICJksxkuXlxhZmbGM/+tqe60s661FYvFiEScjqpOp0OlUqFcLvc0Lv/d3xjjxnC6y0QcCykejxOPx0kmE6TTMzSbLTKZjBv4XSCXy5HL5QDH+mi32+Ryu0QiEVZWVjwhMIae/Tvn2HFdMpkMb3vb2zh37hw3b75xJuIyBxFKEQDI5wuUy2Xm5ubci2i4JCcRIZ1Os7q6ysLCApubm575eVJi0G63KRQKnDt3zkt+KZVKJ3LsYUgmk1y6dJm5uTlEhGaz2eevm55G5re+7Hmwvnh/maVer7tuRaRHWCKRCMlk0nfsFiJOIDKRSLCwsEA0GmV2dpZMJkOr1aJarVIsFtne3ub8+fMkk0n6LwdHCECk41kjly5dIhaLsbGxyc7Ozpm1CkIrArVaja2tLbLZbE/iyLBEIhFmZ2dJp9MsLi6yublFPp+n0WhMXAyMMZRKZTqdDp1Oh2w2O9HjHYVoNMrS0hIXLiyTSCQ8X9wKgP81DP0CYK0H/2e/ZRGJCJGIIw7pdJpSqUS93vDWj0ajpNNpUqmUZ4XMz88Tj8fZ2Nggk6ly4cIF6vU6tVqtpy7+erdaLW/bVCrFuXOz3Llzh1Lp7FkFoRUBcGIDKysrzM7OHrKmEyzsx15ECwsLzM7Oks/n2d7e8cRgkneFWq1Go9EgGo16FsFp6MtOpVJcunSRTCbj+en9jd/vxzsYgv4q22XrfIageE3/Mr8oRCJCMpkEoN3ueNZFIpHw/i/7ajabVKsV5ufn+eAHP8ja2i2efvoZqtUq/ee/0+nQajU9F9EGHzOZjNetXK/Xz4xVEGoRqFSqbG5ukk6niUajPnOzv9Ef7Cr4o9jnzp1jZ2eHnZ0dSqXyxMSgXq9TrVaZmZkhmUx4EfBpYxtDNBql2WwGCkCQrx9E7zLBOS+9y0XAmO4yv8vQ6TifnecDbOCw4fn4/vq0Wi3PinnHOx7koYceolSq8M1vPufGW3pdxna7gzENN/6QJJVKkc1mmZubY27uHGtrtykWi6finBxG6McT2Nraplwu95UGNfrDG7KIc+e5ePEi9913H6ur9zA/P0c8Hh9LXf20222KxSLgmOCZTGbsxzgOlUrFy7sPcgF67/7Di2Pv9n4R6V3mHLPTc/xOp+NabXHP9bMWiiWRSLCychGAv/iLv+DFF18im82yuLjoBY/762u7KK3YWcvg8uXL3H//W7ly5QozMzNDx5umRagtAXDuqNvb22SzWa9vOphBwrC/3PqjNkC1s5Njd3eXSqUytii+MYZiseT5ptlslu3t7bHsexRarRZ37qyzsLAA9Decg83/4TA9d/5++i0DWwdjjJdkBPh6Kpw4wczMDJGIsLZ2myeffNKzaN761reSzc5y69abnonfm9rccbs+TY8rMj8/TzqdJpNJe1bBtPNLBhF6EQDY3NxiefkCs7OHBdiO5ibYKHQ6nWZ+fo5cbpd8fpdyeTw5BtVqlVqtTibjBLtspNzv87bbLdd0PRn/tNPpsLOzQy6X81KAuy84WACCFvT/x/v/825PQ69A+GMK9Xqdra1tZmZmSKVS7nbd2IRjMRg3A7Ht5Qa0Wk0uXLjA7m7Oc+38QmB/U7vd7hEBcFyjK1eukEwmWVtbI58vnMpsQxUBnAvEiQynj2ENHE40GmV+fp5MJsPcnJN9WCjsUalURro7iIh3Z0smEySTSaLRCFeuXCGTyVCvN6jVqtRqNWo1J9rtdNc5wjAp6vU6d+6se7EBP0cTgKDyoADt4GXOMQ3lcpmdnR1WV1cBPBG23Yc2u7A/G/HGjRvs7OS8rkbrWnQDlr0JS/6eik6nQzQa5fz5JRKJBBsbG6yvr1Or1Qf9CVNBRcBle3ublZULQ/QUHBdDPB5ncXHRTV4psbOzw95e8VgJRzZ7zY6M4zwNmSGdTnPt2jUSiQSdTod2u+2l1FarVddnr1KtVqnXa17q7rA598PQ6XTcpJwFzp8/P8QWthENXqPb0P05BsOJciQSYWZmhrm5OaLRqPd77TLb+B0hwM1PsA3ZUK1WvOVOL4OtUwSR/Rmn/iSjdrtNJBJhbm7OCyC+/vrNfd2P00RFwMXGBjKZjM8aCPb5j0e3CyuVcrL8stkse3tFdnZ2KBQKR7owotEoCwvzJJMJ7/vs7Cyp1AyJRMJr0JFIhFQqRSqVYm5uzrvD2X7warVKuez0YtTrDd+DOY614A/uHYVarcbt23eYmUmTTs+4vrpdevT/Nfjww+0nGo2SzWZptZy7v/Xhnf12dyxiSCZjJBIRWi2h03GecbD/WX/Ck7sVIt2cBZvA5LcorUWQyWS4evUqIhFu3LhxaoTgrhSBSCTiptQmmZlx/L9m03nIxF7kQXc+mzHWtQYmF9UVgVQqSSKRIJvNkM8X2N3d9R6dPYxoNEo0GvXMUxHh3Llz2Hz6g7rlEomE+9zBOa/P2/4/zWZz33uz2aLZbLiBtSb1euPAmIbNnwBot1uuyewP1gX79UfBHwcYfJ6M9380Gk2vbpFIxOfDd18gdDrQahk6HcGYjpeQZQO6kYiTUtzp2FhC73UUibQQiRCNRohEou57txMuHo9zzz1XaLfb3Lx5k3p9+q7BXSEC9qJLJBJeRNb/EArgJYQ4pnGdVqtJrVbz7n72Tri9vUM2mx1zt87gKzwSEdJpp69/bu4c+Xye3d08hULhwJ6EWCzW89xDJBIhk8kgwiHmvTWnuxd/PJ4gkUh63Yxd09fm/BuazYaX/VepVNnd3WVra6vHjRER1+w+x9zcPPPzc2SzGUQi3sM/dv/j5WCLwPH5O14uSH9Ksk32saLabHbzDazV4HcfnP+va0lYobDuAnRotwWRFpGIIwhWtI0x7lgGl2g2G9y8+cbUew3OvAjE43EWFhZYXFwglUq5yTNJ76GU/gvP+sn2And8Ysc8rtcb3oXgV+8uw5qxR7nInX1GItGebsV8vkAu58QMghJOuo/mdolGo8RiMc/igaC0W3p+g18M/A3DJkB1x1xI4w94raxcIBaLsb6+7nWJLi4usri4QDabJZVKuU/6OYk1/szBIHrdhaPhb5T+32aMuPs1PWa6c44NnU7bM+H9DzE5uQcdT/T66+yPCdhzYC3M/TkLtuegRTTqiGEsFiMadUY4KhZLU+/aHUoEROSzwD8BNo07VJiILOLMO3ANZ/CQDxtjdsW5Yn4VeBioAD9sjPnG+KvexT4Y4o9G99/J7XfrKuzvHurQ6Tij3dhRhqxCdy+CoDjB0a/c3muqt57Wd7SPCRcKe2xvb/f0M9ukpG6XVDdK7f89Qfj/l/7Pg/L0+4XCDhZy3333kUol3dz5OTKZNIlEYp+A2v/cui7OfzC6NWBdgkG9A1ZYgn7PzEzSuzP3/x9OBuEwzzhYdwCvYdu4gX3Z/Tn7bNNqtd3kIqhWK6RSKW+7aTHUyEIi8j6gBHzOJwK/BOSMMb8gIp8AFowxPy0iDwP/GkcE3g38qjHm3Yfs/9hXhNMgEszPz7O8vMzi4qL3cMjR6e3D7g8eWR+w09mf+z5wj0f6Zb0CY+8i1WqVXG6XXC5HsVhERLh69SqXL1/0XeDdp+lEunf0wRdyV9iClgeJRb8YxOMxWq22dycd9J9bUbIWim04QYlEw/xf3XiAXwCc37L/d9jf2LtuNBp1062dwKq/wVr3cNiG2el0iMed1G1rZVox6H92wq6fz+fZ2tqk1WqfyENnLscfWcgY81VxBg318wjwve7nJ4D/A/y0W/454/zir4nIvPSOOzhWjDHUanU2N7coFPZYWNhhZWXFHYlm8PBhwUjPhRLUQ2BMxLtQBwXf+lNbfbUl6EL1H9+/ro11WPN6cXGB7e0dKpWy62vLvu2sUFnTNyg2YINg/j5t//b+9/7PvWXdB3QO2tbu3loRwRl/4v7mw4XAf478jbu/oduy/rx/wBXXGq1W2zeGgCO6zeZwAmD/PydO0Al0I/1ugf3eaDTY3t6mVOpPV58Oo8QEVnwNex1YcT9fAd70rXfLLZuICFg6nQ7VapVGo8HeXpGFhQUuXrzI/PzcsR4V7uL3pZ3v+y+03nTYwdH54LvufrpiYbe1j8BeuZL0upxsA45EnEbtXLjdbqn9VkD/3bbX/N//e3z/gus7O89BdLPr/H3uB/22blJNt6EPavBHjQ/sdwuC1tkvMLZBtttt7/kO2xXoW4sgNyPot7VaTU8EnF6Ebv6B3yorFotUKpXhf+CEGUtg0BhjjmrSi8hjwGPjOL6fdrtNqVSiWq1SKBQ4f36Jixcves8G9Nbh6PsPSlKxFoMNRPmxF36vODguRdCd0/nuBKZs4wwKcvaOvOvss5+gMrt/91Pg8ff/L/YibwWKS/duHxyH6X+3Qmrv0v7jHCfG0stga6trwfmtB+MFALsNtedXDNwP9FslvbEYEWeIcxtfcqyMJvl8/lSNOTCKCGxYM19ELgGbbvkasOpb7x63rAdjzOPA4zBaTGAQ9im7SqXCzs4OFy9e5MKFC26O/aDWP0q34H4BAHtXCxaHoOCkfbddSv6G718e7Fd7e3e3Od4vCTKrbR3a7VZAI5CeBt1t7LZB+t8PO27XLTjoNwyq4zDnMMidODwIOBz2ru8cR9zh1h3XrNFoUCjkT5UVAKOJwFPAo8AvuO9f9JV/XESexAkMFiYVDzgMq/KFwh7lcoWtrS0uX77M8vKyF12fPIPEIdg12H+XdRq7bfjWgrDBSd+W7vrjrLt/39ba6a/vYIvKb/L3muKDuwndT3QFZbDLEPT5qBy87WExnIP2K8RijsvWbDbdZxdybGxsnLoxBobtHfg8ThDwPLAB/Afgj4AvAG8BbuJ0EebcLsJfBz6A00X4I8aYA6cam4QlMOA4xGIxFhcXXMtgmWh0cFR7Ggw6H91uzE7PuP2Tavz7u90GH2dQd2x3P/3uQNc9cvZpA6lB5+Gg4wbWPKhwJA4SuqBuVuuuFYsl8vm8mwVap9HojzecOIG9A2OZmnxUTkoEfMfznu66555VlpYWvRN4GrCNwklo6fS8ei2FUZ7L9x9vuDvroGMF/W+Duhj7A5WDXZqeI++rw8GnapLn0RGr/vwJp5fKmfegWCx6D4b1xwmmjIpAwHG9OQWuXn2Lm3YrJyoI/t6DbmNve2b/IJ9/XKct6C4XHA8I3j4oINhfPmgdZ7+H++LdOg77o8dz7oL/m95ro1arsbubJ5fLeQ9ijSu+MAFUBA44vjfYRCIRJxqNEY/HiESixGJRdwKMqJev7/TBR72ccNsnD+x799PfO2Abe29f/qAGfpjZf1z/tbvdUS0AZ5vBx+y3BnobVXBi1uEMs974BDzIoqlWa+Tzu17Dt+MWngEmNiHpmccY442N5yfI17Uv/8Mo/txzJ+03zcrKCnNzc/jN+v7EkeEbwjB+/7AXfr9Y7M+DGPaYhxlLg9yM0RpM/0HH3/gGdW2KCMVikVdeeYVicfrT0Y0LFYED2N9/3/1+UIQ3l4vSarW9GXH82w7ODRjPxRwUYe9bY2A/t682wx7tkLp0BcefMBO87sGJVCIQiTjC2/vfj+euPyiGYd/tcZ25Be4eAQAdbXgitNttdnZ22Nra7hnAwnL09n6wud67TOg2dOkpsy+bXdft4/cvH7JGx2h7XQHsKcXfHbj/OOJaWDGi0YOGfjsefh8/+IGp7nJnKPncRIdmmwZqCUyIarXKG2+80fPYraXb+IyvLLgfvou9UAet0P/cA1jTv98s709eOslOkWAh6P4nvb+vN0hr8yXGweF3/t7jl0pl7ty5cyoHCh0VFYEJUqvVuHnzJo1G3Rt11t/YDzOBg0XhKC022ILo/X70gOJB0f7BDBY4/zh/hzXy44rAoN6KYQSg3W6zublJqVQem9t2mlARmDDNZpNbt9Zotdq85S2r7mPOEYL87v3Rc+n7fvCxBpvKBwX5grY5PGNvGPypxP4yv5Xi71k5fH/Ddb0N+h8Ob/z73QJwJq/d2to6VTM/jxMVgROg0+mwvr5Ou93i6tWr3mCmBwXL9pvwo5jtwRbBwQ2qVwiC9nc0bJKNPXbvqLzOe7fnpNtg/cHF41oBhwf9/J/9r1qtzvr6+qnL9x8nKgInRKfTYWPDGUTi2rVrzM2d2ycEfkE4+A7ctQqGN833WxLDxSHGaf7uz0nwP+Lb+8xE9z/ornv0Ix7U3XdQ47fnYnNzg1wud1f1BvSjInDC7Ozs0G63uffe6ywszBONRrwG0CsE3fHxoD9+0Ns4D4qY+7fpjwXYHgSRwwOS3eMd1xw5qI729x+8h6O4Agc3fqc+gxq/dU92d3fZ2Ni8K4OBflQEpkA+n+ell17m+vVrLC8v90x42f+I8aBA4nBdZYOCft14Q5DgBDP+LoTDf0JvnsFhIjCooe9fdrAAiAj1ep3bt2+zt7d3VwYD/agITIlSqcTLL79Co9Hknnuu9CQVBYsB2Mbr0HvnDHYfgu/yXVO73wU5zD0YH/2N86AkIhE50BzvNnj7HiwC3Zf9HukTAKes1Wqxtnbbdd9O12O/k0BFYIrUajVeffVVms0G165d6xnjIEgI/A20Kwxd+gNtbumBd/l+a2M4q2A0+gUgKO7gb5TdmEn/U4TBAb9gf99ZP6jR98cBtrd3uH379qmZIWjSqAhMmVar5c5NV2d19R5SqZRv5hp7Ifc2BIegO3bXbfBK+twH/3ML/kbktw786w8+1tEJCsr1D5AS5Jt3n8HfP0DLMF18w7oAAMVikVu3brG3tzf6Dz4jqAicAjqdDrdv32Z7e5tkMkk8HnfH859x5xFMkkgkvamt7Lh1/a/+RuIf6qq/RyF4xN/gBKbeCP1hfnlgac/+e62djm+bbqO0AmCHKO/fT/+++s39gwJ/g0SgUqnw5pu32N7evqt7A/o5VAQkeOKR/wT8U6ABvIozelBenGHJXwBedDf/mjHmxydR8buRRqMRGIkWccY9SCYTxGJx97HnJPF4wnuPxXpn2AkWCXvn9OcAWFfALxbBfnqvqByN/np0n6bs7q9/Is+g2X+C9nd4o+8uD3IBRJwhwNbX17lz585dmxQ0iEPHE5DgiUfeD/xvY0xLRH4RwDgTj1wDvmTXG7oSUx5P4CxjZ/eJx+Pe50TCmQgjkUh4YyDE4zGi0ZjX0JxX9y7oNAy8cn+3JeyPzh/2xN8gf93e/XuDmk5DtOLlTAE2rAAc3OiD7/y9QtBqtdjY2OTll18mn8/fzb0BxxtPwARMPGKM+VPf168B/3zk6inHws7sc1BfdrfBR72xD/zviUTcsyZmZtLMzma96cT8jT/IVRjUDRnkq/un5urWzWmQVoz8s/b073uQ/98VsoOCgJGe5cY4rka9Xiefz/PGG29SKBTuZgEYyDhiAv8SZ05Cy3UR+WtgD/h3xpg/D9pIJjTvgLIfp/EBHDzIpYi4Mx0tsrx83psT0bEMgmIF+wUgyEf3D5/WXQ+v8fsDgL0DcQ5O9wU818fvQgSLQte9aTad2agrlao7FuAe+XyecrkcqjiAn2FHG75GgJkvIj8HvBP4AWOMEZEkkDXG7IjIQzgjEn+XMebAUKu6A6ePTCbD/Pwcy8vLnhjA/jyG/usnSAT6LQBrkkciUc/18M9kFLQ/XwmRiPgsmQiDTH9jurMkVatVyuUKpVLJa/TVanXao/+eNOMdXkxEfhgnYPgPjXslGGPqQN39/IyIvAp8B3DgkOPK6aNcLlMul8nnCywszLO0dN5zEyAoJhD8pKJ/hOSumd7t9rTTmQ26C/u3A8eCcCYTTe6bSt2ubxu90/DL7O0VKZWKlEplms1maO/4gziWCIjIB4B/C/w9Y0zFV76MM1NxW0TuBe4HXhtLTZWpUC6XqVQq5PN5lpaWWFo6Tzab8Rrg/kFCTE+D7A0u9gYN7VTwh1mjdjt7TDsnot23nd7LNvpyuUKhUKBarVCt1kIX7T8qw3QRehOPiMgtnIlHfgZIAl92T7jtCnwf8B9FpAl0gB83xuQmVHflhDDGUCqVqVSq5PMFlpaWmJ+fI51OB3YZ9otAEP6p1HxH8u9lXx3sdjag5wwOW6VUKlEqldzvZRoNvdsfBR1yXDkyznTpGRYWFllYmGdmZmZfYO6gmEG3l+FomYh2u0ajwc5OjkKhQK1Wo1arhSLHfwzokOPKeGi1WuTzBc/sXlpaZH5+nlQqRTQaHcK8P97kHHYbJ7Pvzbv+Ed+TQkVAOTbNZpNcLkel4ojB8vIyCwsLRKPRwPWD8wyOhjGGarWqd/4xoiKgjEytVqNer1MuVygWS5w/v0Qmk+lp8MdNNw6iXK6ozz9GVASUsWCM8ebiKxb3WF6+wPnzSz1WwfGsgN6EpE6nQ71eH73CiodOPqKMlWazSaGwR6GQp9FoBMykfFR6LQibJq2MDxUBZSLYjL7jMkgzms2mxgPGjIqAMnY6nQ57e0VqtZovZ+BoowUPCiHU642wpfpOHBUBZSJUq9WeMfqcVOHDtrJPDg5a5oy5cBpyW+4mVASUidBut9ndzZHP54+wlR3wJHiZ8xRgQ3sGxoyKgDIx6vUGW1tbIwbyegcyqdW0Z2DcqAgoE8MYQ7FYIpfLjaV3oNPpUKtV1R0YMyoCykRpNptsbW1RLpdH3le73abR0CcCx42KgDJRjDFUKhV2d3dH9uXr9br2DEwAFQFl4jSbLba3dygWi27J8cx57R6cDCoCyolQq9XY2dlxB/g4uK9wkMvfaNS1Z2ACHCoCIvJZEdkUked9ZZ8UkTURedZ9Pexb9jMi8oqIvCgi3zepiitni3a7TS63y+7u7pEmMPFPu9ZstjQoOAGGsQR+C/hAQPmvGGMecF9/DCAibwc+AnyXu81/EZHg50qV0GGH9242m0M3Zr8g6DMDk+FQETDGfBUYdoiwR4AnjTF1Y8wN4BXgXSPUT7mLMMawt1ccYA3sH868O/eAoV6vU6/X1RKYAKPEBD4uIs+57sKCW3YFeNO3zi23bB8i8piIPC0iOhJxiKjXndhAtdrf39+dn8C+6vU6udwuN268zgsv/C2FQmFq9b6bOe5jXp8Bfh5Hpn8e+BTOJCRDY4x5HHgcdIzBMGEMbgLRrjsDc8SbEajdblOr1b0JQSqVit79T4BjiYAxZsN+FpHfAL7kfl0DVn2r3uOWKYqHHZYsk8mQyaSpVqvs7ua9gUP1UeGT5bjzDlwyxtxxv34IsD0HTwG/KyKfBi7jzDvwVyPXUrnrKJfLvPbaa4BxBx/Ru/20OO68A98rIg/guAOvAz8GYIz5loh8Afg20AI+ZozR7A5lH85zALVpV0NB5x1QlDAROO+AZgwqSshREVCUkKMioCghR0VAUUKOioCihBwVAUUJOSoCihJyVAQUJeSoCChKyFERUJSQoyKgKCFHRUBRQo6KgKKEHBUBRQk5KgKKEnKOO+/A7/nmHHhdRJ51y6+JSNW37L9OsO6KooyBYYYX+y3g14HP2QJjzL+wn0XkU4B/GNhXjTEPjKl+iqJMmENFwBjzVRG5FrRMRAT4MPAPxlwvRVFOiFFjAt8DbBhjXvaVXReRvxaR/ysi3zPi/hVFmTDHnXfA8lHg877vd4C3GGN2ROQh4I9E5LuMMXv9G4rIY8BjIx5fUZQRObYlICIx4AeA37Nl7vRjO+7nZ4BXge8I2t4Y87gx5p1BAx8qinJyjOIO/CPgb40xt2yBiCzbCUhF5F6ceQdeG62KiqJMkmG6CD8P/D/gbSJyS0R+1F30EXpdAYD3Ac+5XYb/HfhxY8ywk5kqijIFdN4BRQkPOu+Aoij7URFQlJCjIqAoIUdFQFFCjoqAooQcFQFFCTkqAooSclQEFCXkqAgoSshREVCUkKMioCghR0VAUUKOioCihBwVAUUJOSoCihJyhhlUZFVE/kxEvi0i3xKRn3DLF0XkyyLysvu+4JaLiPyaiLwiIs+JyIOT/hGKohyfYSyBFvBTxpi3A+8BPiYibwc+AXzFGHM/8BX3O8AHcYYVux9nINHPjL3WiqKMjUNFwBhzxxjzDfdzEXgBuAI8AjzhrvYE8P3u50eAzxmHrwHzInJp3BVXFGU8HCkm4E5C8g7gL4EVY8wdd9E6sOJ+vgK86dvsllumKMopZOh5B0QkC/w+8JPGmD1n8iEHY4w56jiBOu+AopwOhrIERCSOIwC/Y4z5A7d4w5r57vumW74GrPo2v8ct60HnHVCU08EwvQMC/CbwgjHm075FTwGPup8fBb7oK/8ht5fgPUDB5zYoinLKOHTIcRF5L/DnwDeBjlv8szhxgS8AbwFuAh82xuRc0fh14ANABfgRY8zThxxDhxxXlMkTOOS4zjugKOFB5x1QFGU/KgKKEnJUBBQl5KgIKErIURFQlJCjIqAoIUdFQFFCjoqAooQcFQFFCTkqAooSclQEFCXkqAgoSshREVCUkKMioCghR0VAUUKOioCihBwVAUUJOSoCihJyhh5yfMJsA2X3/axynrNdfzj7v+Gs1x8m+xuuBhWeijEGAUTk6bM8/PhZrz+c/d9w1usP0/kN6g4oSshREVCUkHOaRODxaVdgRM56/eHs/4azXn+Ywm84NTEBRVGmw2myBBRFmQJTFwER+YCIvCgir4jIJ6Zdn2ERkddF5Jsi8qyIPO2WLYrIl0XkZfd9Ydr19CMinxWRTRF53lcWWGd3Lslfc8/LcyLy4PRq7tU1qP6fFJE19zw8KyIP+5b9jFv/F0Xk+6ZT6y4isioifyYi3xaRb4nIT7jl0z0HxpipvYAo8CpwL5AA/gZ4+zTrdIS6vw6c7yv7JeAT7udPAL847Xr21e99wIPA84fVGXgY+B+AAO8B/vKU1v+TwL8JWPft7vWUBK6711l0yvW/BDzofp4FXnLrOdVzMG1L4F3AK8aY14wxDeBJ4JEp12kUHgGecD8/AXz/9KqyH2PMV4FcX/GgOj8CfM44fA2Yt1PRT4sB9R/EI8CTxpi6MeYG8ArO9TY1jDF3jDHfcD8XgReAK0z5HExbBK4Ab/q+33LLzgIG+FMReUZEHnPLVkx3GvZ1YGU6VTsSg+p8ls7Nx11z+bM+F+xU119ErgHvwJnde6rnYNoicJZ5rzHmQeCDwMdE5H3+hcax585U18tZrDPwGeA+4AHgDvCpqdZmCEQkC/w+8JPGmD3/smmcg2mLwBqw6vt+j1t26jHGrLnvm8Af4piaG9Zcc983p1fDoRlU5zNxbowxG8aYtjGmA/wGXZP/VNZfROI4AvA7xpg/cIuneg6mLQJfB+4XkesikgA+Ajw15TodiohkRGTWfgbeDzyPU/dH3dUeBb44nRoeiUF1fgr4ITdC/R6g4DNZTw19PvKHcM4DOPX/iIgkReQ6cD/wVyddPz8iIsBvAi8YYz7tWzTdczDNaKkvAvoSTvT256ZdnyHrfC9O5PlvgG/ZegNLwFeAl4H/BSxOu6599f48jsncxPEvf3RQnXEi0v/ZPS/fBN55Suv/2279nnMbzSXf+j/n1v9F4IOnoP7vxTH1nwOedV8PT/scaMagooScabsDiqJMGRUBRQk5KgKKEnJUBBQl5KgIKErIURFQlJCjIqAoIUdFQFFCzv8H3hh6pNjrgFoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensor_image = data['img_rgb'][:3,...]\n",
    "print(tensor_image.shape)\n",
    "plt.imshow(  tensor_image.permute(1, 2, 0)  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 224, 224])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f37efa504c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensor_image = data['img_mask']\n",
    "print(tensor_image.shape)\n",
    "plt.imshow(  tensor_image.permute(1, 2, 0)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1024])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['pcl'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /home/varsha/.local/lib/python3.8/site-packages (1.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256, 14, 14])\n",
      "torch.Size([2, 50176])\n",
      "before view:  torch.Size([2, 3072])\n",
      "after view:  torch.Size([2, 3, 1024])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             896\n",
      "              ReLU-2         [-1, 32, 112, 112]               0\n",
      "            Conv2d-3           [-1, 64, 56, 56]          18,496\n",
      "              ReLU-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5          [-1, 128, 28, 28]          73,856\n",
      "              ReLU-6          [-1, 128, 28, 28]               0\n",
      "            Conv2d-7          [-1, 256, 14, 14]         295,168\n",
      "              ReLU-8          [-1, 256, 14, 14]               0\n",
      "            Linear-9                  [-1, 128]       6,422,656\n",
      "             ReLU-10                  [-1, 128]               0\n",
      "           Linear-11                  [-1, 128]          16,512\n",
      "             ReLU-12                  [-1, 128]               0\n",
      "           Linear-13                 [-1, 3072]         396,288\n",
      "================================================================\n",
      "Total params: 7,223,872\n",
      "Trainable params: 7,223,872\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 11.51\n",
      "Params size (MB): 27.56\n",
      "Estimated Total Size (MB): 39.64\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from src.network_architecture.recon_model import ReconstructionNet\n",
    "from torchsummary import summary\n",
    "\n",
    "cnn3d = ReconstructionNet()\n",
    "print(summary(cnn3d, input_size=(3,224,224))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvarsha_r\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/varsha/Code/ml3d/project/ssl_3d_recon_pytorch/wandb/run-20220706_233608-1oh0udfa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/varsha_r/recon_run/runs/1oh0udfa\" target=\"_blank\">quiet-plant-23</a></strong> to <a href=\"https://wandb.ai/varsha_r/recon_run\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "(1, 1)\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[000/00000] val_loss: 0.028\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[001/00000] val_loss: 0.027\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[002/00000] val_loss: 0.026\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[003/00000] val_loss: 0.026\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[004/00000] val_loss: 0.025\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[005/00000] val_loss: 0.024\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[006/00000] val_loss: 0.024\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[007/00000] val_loss: 0.023\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[008/00000] val_loss: 0.022\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[009/00000] val_loss: 0.021\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[010/00000] val_loss: 0.020\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[011/00000] val_loss: 0.019\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[012/00000] val_loss: 0.018\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[013/00000] val_loss: 0.017\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[014/00000] val_loss: 0.015\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[015/00000] val_loss: 0.014\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[016/00000] val_loss: 0.013\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[017/00000] val_loss: 0.012\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[018/00000] val_loss: 0.011\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[019/00000] val_loss: 0.010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[020/00000] val_loss: 0.009\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[021/00000] val_loss: 0.008\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[022/00000] val_loss: 0.007\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[023/00000] val_loss: 0.007\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[024/00000] val_loss: 0.006\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[025/00000] val_loss: 0.005\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[026/00000] val_loss: 0.005\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[027/00000] val_loss: 0.004\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[028/00000] val_loss: 0.004\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[029/00000] val_loss: 0.003\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[030/00000] val_loss: 0.003\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[031/00000] val_loss: 0.003\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[032/00000] val_loss: 0.002\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[033/00000] val_loss: 0.002\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[034/00000] val_loss: 0.002\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[035/00000] val_loss: 0.002\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[036/00000] val_loss: 0.002\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[037/00000] val_loss: 0.001\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[038/00000] val_loss: 0.001\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[039/00000] val_loss: 0.001\n",
      "0\n",
      "torch.Size([3, 224, 224])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[040/00000] val_loss: 0.001\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[041/00000] val_loss: 0.001\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[042/00000] val_loss: 0.001\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[043/00000] val_loss: 0.001\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[044/00000] val_loss: 0.001\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[045/00000] val_loss: 0.001\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[046/00000] val_loss: 0.001\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[047/00000] val_loss: 0.000\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[048/00000] val_loss: 0.000\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[049/00000] val_loss: 0.000\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[050/00000] val_loss: 0.000\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[051/00000] val_loss: 0.000\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[052/00000] val_loss: 0.000\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[053/00000] val_loss: 0.000\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[054/00000] val_loss: 0.000\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[055/00000] val_loss: 0.000\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[056/00000] val_loss: 0.000\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[057/00000] val_loss: 0.000\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[058/00000] val_loss: 0.000\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "prediction shape:  torch.Size([1, 3, 1024])\n",
      "0\n",
      "torch.Size([3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "[059/00000] val_loss: 0.000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.00012</td></tr><tr><td>val_loss</td><td>0.00011</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">quiet-plant-23</strong>: <a href=\"https://wandb.ai/varsha_r/recon_run/runs/1oh0udfa\" target=\"_blank\">https://wandb.ai/varsha_r/recon_run/runs/1oh0udfa</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220706_233608-1oh0udfa/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from src.training import train_recon\n",
    "config = {\n",
    "     'category' :  '02691156',\n",
    "    'experiment_name': 'recon_overfitting',\n",
    "    'device': 'cpu',                      # change this to cpu if you do not have a GPU\n",
    "    'is_overfit': True,                      # True since we're doing overfitting\n",
    "    'batch_size': 2,\n",
    "    'resume_ckpt': None,\n",
    "    'learning_rate': 0.0005,\n",
    "    'max_epochs': 60,\n",
    "    'print_every_n': 1,\n",
    "    'validate_every_n': 1,\n",
    "}\n",
    "\n",
    "train_recon.train(config)  # should be able to get ~0 loss, 100% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReconstructionNet(\n",
       "  (relu): ReLU()\n",
       "  (cnn1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (cnn2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (cnn3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (cnn4): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (linear1): Linear(in_features=50176, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (linear3): Linear(in_features=128, out_features=3072, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ReconstructionNet()\n",
    "ckpt = f'src/runs/{config[\"experiment_name\"]}/model_best.ckpt'\n",
    "model.load_state_dict(torch.load(ckpt, map_location='cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256, 14, 14])\n",
      "torch.Size([2, 50176])\n",
      "before view:  torch.Size([2, 3072])\n",
      "after view:  torch.Size([2, 3, 1024])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             896\n",
      "              ReLU-2         [-1, 32, 112, 112]               0\n",
      "            Conv2d-3           [-1, 64, 56, 56]          18,496\n",
      "              ReLU-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5          [-1, 128, 28, 28]          73,856\n",
      "              ReLU-6          [-1, 128, 28, 28]               0\n",
      "            Conv2d-7          [-1, 256, 14, 14]         295,168\n",
      "              ReLU-8          [-1, 256, 14, 14]               0\n",
      "            Linear-9                  [-1, 128]       6,422,656\n",
      "             ReLU-10                  [-1, 128]               0\n",
      "           Linear-11                  [-1, 128]          16,512\n",
      "             ReLU-12                  [-1, 128]               0\n",
      "           Linear-13                 [-1, 3072]         396,288\n",
      "================================================================\n",
      "Total params: 7,223,872\n",
      "Trainable params: 7,223,872\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 11.51\n",
      "Params size (MB): 27.56\n",
      "Estimated Total Size (MB): 39.64\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "from os.path import join, abspath, basename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rendered_path = \"src/data/ShapeNet_rendered\"  \n",
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "\n",
    "img_path = join(rendered_path , config['category']+'/f7110ecac70994a83820d8f180caa23a/render_0.png')\n",
    "rgb_image =  cv2.imread(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = transform(rgb_image)\n",
    "print(input_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 50176])\n",
      "before view:  torch.Size([1, 3072])\n",
      "after view:  torch.Size([1, 3, 1024])\n",
      "torch.Size([1, 3, 1024])\n"
     ]
    }
   ],
   "source": [
    "prediction = model(torch.unsqueeze(data['img_rgb'], 0))\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import torch\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "\n",
    "data_pcl = torch.reshape(prediction, ( 1024, 3)).detach().numpy()\n",
    "print(data_pcl.shape)\n",
    "\n",
    "pcd.points = o3d.utility.Vector3dVector(data_pcl)\n",
    "o3d.io.write_point_cloud(\"./data_3.ply\", pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = np.load('src/data/splits/shapenet/images_list_02691156_train.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items[:1].dump('src/data/splits/shapenet/images_list_02691156_overfit.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
