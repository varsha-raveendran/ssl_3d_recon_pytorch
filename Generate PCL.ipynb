{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a1e59df",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb41fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'02691156': 'airplane', '02933112': 'cabinet', '02958343': 'car', '03001627': 'chair', '03636649': 'lamp', '04256520': 'sofa', '04379243': 'table', '04530566': 'watercraft'}\n"
     ]
    }
   ],
   "source": [
    "from src.network_architecture.recon_model import ReconstructionNet\n",
    "from src.network_architecture.pose_net import PoseNet\n",
    "from src.training import train_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45d8b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'iso': True,\n",
    "    'use_symmetry_loss': True,\n",
    "     \"use_pretrained\" : True,\n",
    "    'experiment_name' : 'v1',\n",
    "    'device': 'cuda:0',  # change this to cpu if you do not have a GPU\n",
    "    'is_overfit': True,\n",
    "    'category' : '02691156',\n",
    "    'batch_size': 4,\n",
    "    'resume_ckpt': None,\n",
    "    'learning_rate': 0.001,\n",
    "    'max_epochs': 1,\n",
    "    'print_every_n': 1,\n",
    "    'validate_every_n': 1,\n",
    "    'learning_rate_pose_net' : 0.0005,\n",
    "    'learning_rate_recon_net' : 0.0005,\n",
    "    'n_proj' : 5,\n",
    "    'lambda_ae' : 100.0,\n",
    "    'lambda_3d' : 10000.0,\n",
    "    'lambda_pose' : 1.0,\n",
    "    'lambda_ae_mask' : 1000,\n",
    "    'lambda_mask_fwd' : .00001,\n",
    "    'lambda_mask_bwd' : .00001,\n",
    "    'lambda_symm' : 1,\n",
    "    'lambda_mask_pose' : 1.0,\n",
    "    'lambda_ae_pose' : 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6d4456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.shapenet import ShapeNet\n",
    "trainset = ShapeNet('test',config['category'], config['n_proj'])\n",
    "#trainloader = torch.utils.data.DataLoader(trainset, batch_size=config['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e4e15a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation import save_pcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ce84024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimising item:  c5d748c352d8eeeb3d4e343a1ac21b93\n",
      "**********************************************\n",
      "Step :  0\n",
      "Iteration :  0\n",
      "Loss :  -135.7188350911008\n",
      "Optimising item:  7f09b3b11ae3f22dbe13ce34aa7c0c1c\n",
      "**********************************************\n",
      "Step :  0\n",
      "Iteration :  0\n",
      "Loss :  -112.37796422044084\n",
      "Optimising item:  4b20c1736440ff9d90dd6eb126f6cbbb\n",
      "**********************************************\n",
      "Step :  0\n",
      "Iteration :  0\n",
      "Loss :  -100.06914597238264\n",
      "Optimising item:  52ca6970fb09b561f9f7510373841dd9\n",
      "**********************************************\n",
      "Step :  0\n",
      "Iteration :  0\n",
      "Loss :  -99.69179586964844\n",
      "Optimising item:  d171967c6353177bb87697d3904b168b\n",
      "**********************************************\n",
      "Step :  0\n",
      "Iteration :  0\n",
      "Loss :  -114.47942111612251\n",
      "Optimising item:  739c8cadb1db6db39a6e43b878d5b335\n",
      "**********************************************\n",
      "Step :  0\n",
      "Iteration :  0\n",
      "Loss :  -98.98710595216774\n",
      "Optimising item:  350110d2828b3b927370804727e72eb2\n",
      "**********************************************\n",
      "Step :  0\n",
      "Iteration :  0\n",
      "Loss :  -89.86275461434309\n",
      "Optimising item:  26830050c44b5a8f9cf081e9d8a0b57f\n",
      "**********************************************\n",
      "Step :  0\n",
      "Iteration :  0\n",
      "Loss :  -157.39747933193073\n",
      "Optimising item:  350d12f5290908c7f446f92b52bbd82a\n",
      "**********************************************\n",
      "Step :  0\n",
      "Iteration :  0\n",
      "Loss :  -98.18219867263116\n",
      "Optimising item:  3a18489f9615a350e768735f27170bc4\n",
      "**********************************************\n",
      "Step :  0\n",
      "Iteration :  0\n",
      "Loss :  -102.6515437224934\n",
      "Optimising item:  32b6448c0864812729348d14ca881f7d\n",
      "**********************************************\n",
      "Step :  0\n",
      "Iteration :  0\n",
      "Loss :  -145.60165532821358\n",
      "Optimising item:  62bd247f0e8081a171d03b466c72ce41\n",
      "**********************************************\n",
      "Step :  0\n",
      "Iteration :  0\n",
      "Loss :  -122.95246888423011\n",
      "Optimising item:  3cdf7ea70c5a8471f446f92b52bbd82a\n",
      "**********************************************\n",
      "Step :  0\n",
      "Iteration :  0\n",
      "Loss :  -116.86596550974093\n",
      "Optimising item:  9300dc1ca5f16b074f95630cc18536e0\n",
      "**********************************************\n",
      "Step :  0\n",
      "Iteration :  0\n",
      "Loss :  -132.15538131059702\n",
      "Optimising item:  1ed9876ed48c145d663e90eaf6b4ca52\n",
      "**********************************************\n",
      "Step :  0\n",
      "Iteration :  0\n",
      "Loss :  -128.78968884926783\n",
      "Optimising item:  df6aae66a8c378ae9029a69fa5fc9ad\n",
      "**********************************************\n",
      "Step :  0\n",
      "Iteration :  0\n",
      "Loss :  -120.61355135612379\n",
      "Optimising item:  6896058e4bc0be46bdf566b587d6b21\n",
      "**********************************************\n",
      "Step :  0\n",
      "Iteration :  0\n",
      "Loss :  -149.73683954944542\n",
      "Optimising item:  a8471560d4dd5a31ebc34aaab30ca460\n",
      "**********************************************\n",
      "Step :  0\n",
      "Iteration :  0\n",
      "Loss :  -108.7301608446803\n",
      "Optimising item:  b2960c2be8fad9dac140e34b6af37a1d\n",
      "**********************************************\n",
      "Step :  0\n",
      "Iteration :  0\n",
      "Loss :  -126.08529237041441\n",
      "Optimising item:  1e7dbf0057e067586e88b250ea6544d0\n",
      "**********************************************\n",
      "Step :  0\n",
      "Iteration :  0\n",
      "Loss :  -99.91508233675586\n",
      "Optimising item:  c2f3e3a227aee9ecca8607f540cc62ba\n",
      "**********************************************\n",
      "Step :  0\n",
      "Iteration :  0\n",
      "Loss :  -131.24956016306857\n",
      "Optimising item:  dcca40aae3eb0c8757bef59252fb18b5\n",
      "**********************************************\n",
      "Step :  0\n",
      "Iteration :  0\n",
      "Loss :  -138.16713918440294\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msave_pcl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Projects\\ML3D\\Final Project\\ssl_3d_recon_pytorch\\src\\evaluation\\save_pcl.py:242\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    239\u001b[0m trainset \u001b[38;5;241m=\u001b[39m ShapeNet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m], config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_proj\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m trainset:\n\u001b[1;32m--> 242\u001b[0m     \u001b[43moptimise_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Projects\\ML3D\\Final Project\\ssl_3d_recon_pytorch\\src\\evaluation\\save_pcl.py:24\u001b[0m, in \u001b[0;36moptimise_and_save\u001b[1;34m(item, config)\u001b[0m\n\u001b[0;32m     21\u001b[0m gt_pose \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munsqueeze(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgt_pose\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#Initialise models and load trained checkpoints\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m recon_net \u001b[38;5;241m=\u001b[39m \u001b[43mReconstructionNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m pose_net \u001b[38;5;241m=\u001b[39m PoseNet()\n\u001b[0;32m     26\u001b[0m ckpt_recon \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc/runs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/recon_model_best.ckpt\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mD:\\Projects\\ML3D\\Final Project\\ssl_3d_recon_pytorch\\src\\network_architecture\\recon_model.py:30\u001b[0m, in \u001b[0;36mReconstructionNet.__init__\u001b[1;34m(self, return_feat)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolor_cnn1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv2d(in_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, out_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m, kernel_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, padding\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolor_cnn2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv2d(in_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m, out_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m, kernel_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, padding\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolor_linear1 \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolor_linear2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(in_features\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m , out_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolor_linear3 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(in_features\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m , out_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml3d2\\lib\\site-packages\\torch\\nn\\modules\\linear.py:90\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister_parameter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml3d2\\lib\\site-packages\\torch\\nn\\modules\\linear.py:96\u001b[0m, in \u001b[0;36mLinear.reset_parameters\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset_parameters\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;66;03m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[39;00m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;66;03m# uniform(-1/sqrt(in_features), 1/sqrt(in_features)). For details, see\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/57109\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m     \u001b[43minit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkaiming_uniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     98\u001b[0m         fan_in, _ \u001b[38;5;241m=\u001b[39m init\u001b[38;5;241m.\u001b[39m_calculate_fan_in_and_fan_out(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml3d2\\lib\\site-packages\\torch\\nn\\init.py:410\u001b[0m, in \u001b[0;36mkaiming_uniform_\u001b[1;34m(tensor, a, mode, nonlinearity)\u001b[0m\n\u001b[0;32m    408\u001b[0m bound \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m3.0\u001b[39m) \u001b[38;5;241m*\u001b[39m std  \u001b[38;5;66;03m# Calculate uniform bounds from standard deviation\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbound\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_pcl.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "134dcde1",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_pose\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mD:\\Projects\\ML3D\\Final Project\\ssl_3d_recon_pytorch\\src\\data\\shapenet.py:45\u001b[0m, in \u001b[0;36mShapeNet.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m#rgb_image =  cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\u001b[39;00m\n\u001b[0;32m     44\u001b[0m rgb_image \u001b[38;5;241m=\u001b[39m  cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[1;32m---> 45\u001b[0m rgb_image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m img_tensor \u001b[38;5;241m=\u001b[39m transform(rgb_image)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# print(img_tensor.shape)\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "trainset[0]['random_pose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976bc718",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset[0]['random_pose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20750b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml3d2] *",
   "language": "python",
   "name": "conda-env-ml3d2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
