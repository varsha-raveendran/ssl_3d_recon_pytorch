{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5380f9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12efd1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36931b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'02691156': 'airplane', '02933112': 'cabinet', '02958343': 'car', '03001627': 'chair', '03636649': 'lamp', '04256520': 'sofa', '04379243': 'table', '04530566': 'watercraft'}\n"
     ]
    }
   ],
   "source": [
    "from src.network_architecture.recon_model import ReconstructionNet\n",
    "from src.network_architecture.pose_net import PoseNet\n",
    "from src.training import train_full\n",
    "from src.loss import loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e746fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"use_pretrained\" : False,\n",
    "    'experiment_name' : 'v1',\n",
    "    'device': 'cuda:0',  # change this to cpu if you do not have a GPU\n",
    "    'is_overfit': True,\n",
    "    'category' : '03001627',\n",
    "    'batch_size': 4,\n",
    "    'resume_ckpt': None,\n",
    "    'learning_rate': 0.0005,\n",
    "    'max_epochs': 1000,\n",
    "    'print_every_n': 1,\n",
    "    'validate_every_n': 1,\n",
    "    'learning_rate_pose_net' : 0.0005,\n",
    "    'learning_rate_recon_net' : 0.0005,\n",
    "    'n_proj' : 5,\n",
    "    \"lambda_3d\": 10000.0,\n",
    "    \"lambda_ae\": 1000.0,\n",
    "    \"lambda_ae_mask\": 1000.0,\n",
    "    \"lambda_ae_pose\": 1.0,\n",
    "    \"lambda_mask_bwd\": 0.0001,\n",
    "    \"lambda_mask_fwd\": 0.0001,\n",
    "    \"lambda_mask_pose\": 1.0,\n",
    "    \"lambda_pose\": 1.0,\n",
    "    \"lambda_symm\": 0.0,\n",
    "    'use_symmetry_loss':False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67c1b064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ql98ojwi) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.391 MB of 0.391 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Pose_loss</td><td>▁</td></tr><tr><td>Recon_loss</td><td>▁</td></tr><tr><td>Total Loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Pose_loss</td><td>1.02502</td></tr><tr><td>Recon_loss</td><td>-345.08746</td></tr><tr><td>Total Loss</td><td>-344.06244</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">skilled-music-39</strong>: <a href=\"https://wandb.ai/ssl_3d/v1/runs/ql98ojwi\" target=\"_blank\">https://wandb.ai/ssl_3d/v1/runs/ql98ojwi</a><br/>Synced 5 W&B file(s), 6 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20220721_205643-ql98ojwi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ql98ojwi). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\Projects\\ML3D\\Final Project\\ssl_3d_recon_pytorch\\wandb\\run-20220721_205719-h50igo5c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/ssl_3d/v1/runs/h50igo5c\" target=\"_blank\">colorful-pine-40</a></strong> to <a href=\"https://wandb.ai/ssl_3d/v1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model!\n",
      "**********************************************\n",
      "Epoch :  0\n",
      "Iteration :  0\n",
      "Loss :  -382.804217707028\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  1\n",
      "Iteration :  0\n",
      "Loss :  -440.96582544244035\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  2\n",
      "Iteration :  0\n",
      "Loss :  -513.3080110789678\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  3\n",
      "Iteration :  0\n",
      "Loss :  -639.8431753635284\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  4\n",
      "Iteration :  0\n",
      "Loss :  -875.0920775609366\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  5\n",
      "Iteration :  0\n",
      "Loss :  -1239.6001721198215\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  6\n",
      "Iteration :  0\n",
      "Loss :  -1747.144717276374\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  7\n",
      "Iteration :  0\n",
      "Loss :  -1774.3302629595846\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  8\n",
      "Iteration :  0\n",
      "Loss :  -1474.2633199795641\n",
      "**********************************************\n",
      "Epoch :  9\n",
      "Iteration :  0\n",
      "Loss :  -1534.2453401923567\n",
      "**********************************************\n",
      "Epoch :  10\n",
      "Iteration :  0\n",
      "Loss :  -1636.9781107593333\n",
      "**********************************************\n",
      "Epoch :  11\n",
      "Iteration :  0\n",
      "Loss :  -1707.542178145999\n",
      "**********************************************\n",
      "Epoch :  12\n",
      "Iteration :  0\n",
      "Loss :  -1814.5747275469453\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  13\n",
      "Iteration :  0\n",
      "Loss :  -1877.8605826341454\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  14\n",
      "Iteration :  0\n",
      "Loss :  -1946.2531328809814\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  15\n",
      "Iteration :  0\n",
      "Loss :  -2011.6983346339637\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  16\n",
      "Iteration :  0\n",
      "Loss :  -2057.8367093539805\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  17\n",
      "Iteration :  0\n",
      "Loss :  -2104.5458253712295\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  18\n",
      "Iteration :  0\n",
      "Loss :  -2146.7024759995106\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  19\n",
      "Iteration :  0\n",
      "Loss :  -2162.4071297142323\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  20\n",
      "Iteration :  0\n",
      "Loss :  -2137.9871613451137\n",
      "**********************************************\n",
      "Epoch :  21\n",
      "Iteration :  0\n",
      "Loss :  -2134.699560268885\n",
      "**********************************************\n",
      "Epoch :  22\n",
      "Iteration :  0\n",
      "Loss :  -2191.6449290855526\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  23\n",
      "Iteration :  0\n",
      "Loss :  -2214.412464035875\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  24\n",
      "Iteration :  0\n",
      "Loss :  -2218.036541819226\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  25\n",
      "Iteration :  0\n",
      "Loss :  -2258.992524599917\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  26\n",
      "Iteration :  0\n",
      "Loss :  -2273.3254138614398\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  27\n",
      "Iteration :  0\n",
      "Loss :  -2254.634778476976\n",
      "**********************************************\n",
      "Epoch :  28\n",
      "Iteration :  0\n",
      "Loss :  -2262.8097127868073\n",
      "**********************************************\n",
      "Epoch :  29\n",
      "Iteration :  0\n",
      "Loss :  -2291.709947925669\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  30\n",
      "Iteration :  0\n",
      "Loss :  -2303.829279599419\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  31\n",
      "Iteration :  0\n",
      "Loss :  -2301.7391434391825\n",
      "**********************************************\n",
      "Epoch :  32\n",
      "Iteration :  0\n",
      "Loss :  -2295.557663135763\n",
      "**********************************************\n",
      "Epoch :  33\n",
      "Iteration :  0\n",
      "Loss :  -2315.8474659575036\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  34\n",
      "Iteration :  0\n",
      "Loss :  -2329.9751895156046\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  35\n",
      "Iteration :  0\n",
      "Loss :  -2335.8749258230278\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  36\n",
      "Iteration :  0\n",
      "Loss :  -2339.9401878316066\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  37\n",
      "Iteration :  0\n",
      "Loss :  -2343.5002147517444\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  38\n",
      "Iteration :  0\n",
      "Loss :  -2340.0219218326424\n",
      "**********************************************\n",
      "Epoch :  39\n",
      "Iteration :  0\n",
      "Loss :  -2309.189474457753\n",
      "**********************************************\n",
      "Epoch :  40\n",
      "Iteration :  0\n",
      "Loss :  -2315.7779623314077\n",
      "**********************************************\n",
      "Epoch :  41\n",
      "Iteration :  0\n",
      "Loss :  -2345.3449224962487\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  42\n",
      "Iteration :  0\n",
      "Loss :  -2354.0675729112304\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  43\n",
      "Iteration :  0\n",
      "Loss :  -2339.31567665295\n",
      "**********************************************\n",
      "Epoch :  44\n",
      "Iteration :  0\n",
      "Loss :  -2359.813486422949\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  45\n",
      "Iteration :  0\n",
      "Loss :  -2367.3446647890933\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  46\n",
      "Iteration :  0\n",
      "Loss :  -2355.7099727007812\n",
      "**********************************************\n",
      "Epoch :  47\n",
      "Iteration :  0\n",
      "Loss :  -2355.2502699048837\n",
      "**********************************************\n",
      "Epoch :  48\n",
      "Iteration :  0\n",
      "Loss :  -2370.189126523894\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  49\n",
      "Iteration :  0\n",
      "Loss :  -2379.933570080014\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  50\n",
      "Iteration :  0\n",
      "Loss :  -2376.948889235466\n",
      "**********************************************\n",
      "Epoch :  51\n",
      "Iteration :  0\n",
      "Loss :  -2367.2819293995226\n",
      "**********************************************\n",
      "Epoch :  52\n",
      "Iteration :  0\n",
      "Loss :  -2358.7665351694286\n",
      "**********************************************\n",
      "Epoch :  53\n",
      "Iteration :  0\n",
      "Loss :  -2376.3601333874253\n",
      "**********************************************\n",
      "Epoch :  54\n",
      "Iteration :  0\n",
      "Loss :  -2386.120441984219\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  55\n",
      "Iteration :  0\n",
      "Loss :  -2379.2504547116105\n",
      "**********************************************\n",
      "Epoch :  56\n",
      "Iteration :  0\n",
      "Loss :  -2375.3682699503483\n",
      "**********************************************\n",
      "Epoch :  57\n",
      "Iteration :  0\n",
      "Loss :  -2379.388721857403\n",
      "**********************************************\n",
      "Epoch :  58\n",
      "Iteration :  0\n",
      "Loss :  -2387.6437794431304\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  59\n",
      "Iteration :  0\n",
      "Loss :  -2391.217861968699\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  60\n",
      "Iteration :  0\n",
      "Loss :  -2391.1259401530865\n",
      "**********************************************\n",
      "Epoch :  61\n",
      "Iteration :  0\n",
      "Loss :  -2384.0098771273306\n",
      "**********************************************\n",
      "Epoch :  62\n",
      "Iteration :  0\n",
      "Loss :  -2373.321565185146\n",
      "**********************************************\n",
      "Epoch :  63\n",
      "Iteration :  0\n",
      "Loss :  -2376.5142553844967\n",
      "**********************************************\n",
      "Epoch :  64\n",
      "Iteration :  0\n",
      "Loss :  -2382.7320666076125\n",
      "**********************************************\n",
      "Epoch :  65\n",
      "Iteration :  0\n",
      "Loss :  -2393.142059808636\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  66\n",
      "Iteration :  0\n",
      "Loss :  -2390.858296132923\n",
      "**********************************************\n",
      "Epoch :  67\n",
      "Iteration :  0\n",
      "Loss :  -2379.577904190848\n",
      "**********************************************\n",
      "Epoch :  68\n",
      "Iteration :  0\n",
      "Loss :  -2385.3862112176453\n",
      "**********************************************\n",
      "Epoch :  69\n",
      "Iteration :  0\n",
      "Loss :  -2392.5053007678353\n",
      "**********************************************\n",
      "Epoch :  70\n",
      "Iteration :  0\n",
      "Loss :  -2397.096056464098\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  71\n",
      "Iteration :  0\n",
      "Loss :  -2394.3249742564217\n",
      "**********************************************\n",
      "Epoch :  72\n",
      "Iteration :  0\n",
      "Loss :  -2385.007462499986\n",
      "**********************************************\n",
      "Epoch :  73\n",
      "Iteration :  0\n",
      "Loss :  -2389.0585173450563\n",
      "**********************************************\n",
      "Epoch :  74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :  0\n",
      "Loss :  -2393.9203265806227\n",
      "**********************************************\n",
      "Epoch :  75\n",
      "Iteration :  0\n",
      "Loss :  -2399.3112475494318\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  76\n",
      "Iteration :  0\n",
      "Loss :  -2397.7259057608703\n",
      "**********************************************\n",
      "Epoch :  77\n",
      "Iteration :  0\n",
      "Loss :  -2388.0135239955152\n",
      "**********************************************\n",
      "Epoch :  78\n",
      "Iteration :  0\n",
      "Loss :  -2383.394434443001\n",
      "**********************************************\n",
      "Epoch :  79\n",
      "Iteration :  0\n",
      "Loss :  -2377.716280634882\n",
      "**********************************************\n",
      "Epoch :  80\n",
      "Iteration :  0\n",
      "Loss :  -2394.265594905843\n",
      "**********************************************\n",
      "Epoch :  81\n",
      "Iteration :  0\n",
      "Loss :  -2395.87600050699\n",
      "**********************************************\n",
      "Epoch :  82\n",
      "Iteration :  0\n",
      "Loss :  -2381.79407179788\n",
      "**********************************************\n",
      "Epoch :  83\n",
      "Iteration :  0\n",
      "Loss :  -2393.651369782982\n",
      "**********************************************\n",
      "Epoch :  84\n",
      "Iteration :  0\n",
      "Loss :  -2399.9461667089295\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  85\n",
      "Iteration :  0\n",
      "Loss :  -2398.280636272604\n",
      "**********************************************\n",
      "Epoch :  86\n",
      "Iteration :  0\n",
      "Loss :  -2392.532276030113\n",
      "**********************************************\n",
      "Epoch :  87\n",
      "Iteration :  0\n",
      "Loss :  -2386.635259415382\n",
      "**********************************************\n",
      "Epoch :  88\n",
      "Iteration :  0\n",
      "Loss :  -2395.742284998769\n",
      "**********************************************\n",
      "Epoch :  89\n",
      "Iteration :  0\n",
      "Loss :  -2401.1071165430053\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  90\n",
      "Iteration :  0\n",
      "Loss :  -2401.2988782917323\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  91\n",
      "Iteration :  0\n",
      "Loss :  -2397.690057791163\n",
      "**********************************************\n",
      "Epoch :  92\n",
      "Iteration :  0\n",
      "Loss :  -2391.5466829968695\n",
      "**********************************************\n",
      "Epoch :  93\n",
      "Iteration :  0\n",
      "Loss :  -2391.4454632476168\n",
      "**********************************************\n",
      "Epoch :  94\n",
      "Iteration :  0\n",
      "Loss :  -2391.153514960919\n",
      "**********************************************\n",
      "Epoch :  95\n",
      "Iteration :  0\n",
      "Loss :  -2398.9750363569196\n",
      "**********************************************\n",
      "Epoch :  96\n",
      "Iteration :  0\n",
      "Loss :  -2403.109948589387\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  97\n",
      "Iteration :  0\n",
      "Loss :  -2401.236643707248\n",
      "**********************************************\n",
      "Epoch :  98\n",
      "Iteration :  0\n",
      "Loss :  -2397.297566780657\n",
      "**********************************************\n",
      "Epoch :  99\n",
      "Iteration :  0\n",
      "Loss :  -2384.7154530017815\n",
      "**********************************************\n",
      "Epoch :  100\n",
      "Iteration :  0\n",
      "Loss :  -2387.961692667654\n",
      "**********************************************\n",
      "Epoch :  101\n",
      "Iteration :  0\n",
      "Loss :  -2390.826139854104\n",
      "**********************************************\n",
      "Epoch :  102\n",
      "Iteration :  0\n",
      "Loss :  -2402.139649652367\n",
      "**********************************************\n",
      "Epoch :  103\n",
      "Iteration :  0\n",
      "Loss :  -2396.917299215763\n",
      "**********************************************\n",
      "Epoch :  104\n",
      "Iteration :  0\n",
      "Loss :  -2381.251921609884\n",
      "**********************************************\n",
      "Epoch :  105\n",
      "Iteration :  0\n",
      "Loss :  -2392.3530200131013\n",
      "**********************************************\n",
      "Epoch :  106\n",
      "Iteration :  0\n",
      "Loss :  -2400.0532185236484\n",
      "**********************************************\n",
      "Epoch :  107\n",
      "Iteration :  0\n",
      "Loss :  -2402.0750508369542\n",
      "**********************************************\n",
      "Epoch :  108\n",
      "Iteration :  0\n",
      "Loss :  -2397.14414130094\n",
      "**********************************************\n",
      "Epoch :  109\n",
      "Iteration :  0\n",
      "Loss :  -2390.153845360452\n",
      "**********************************************\n",
      "Epoch :  110\n",
      "Iteration :  0\n",
      "Loss :  -2396.4808549792065\n",
      "**********************************************\n",
      "Epoch :  111\n",
      "Iteration :  0\n",
      "Loss :  -2401.981982673437\n",
      "**********************************************\n",
      "Epoch :  112\n",
      "Iteration :  0\n",
      "Loss :  -2403.440520827012\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  113\n",
      "Iteration :  0\n",
      "Loss :  -2400.082839994811\n",
      "**********************************************\n",
      "Epoch :  114\n",
      "Iteration :  0\n",
      "Loss :  -2392.36449085307\n",
      "**********************************************\n",
      "Epoch :  115\n",
      "Iteration :  0\n",
      "Loss :  -2390.917866918745\n",
      "**********************************************\n",
      "Epoch :  116\n",
      "Iteration :  0\n",
      "Loss :  -2391.1815552419866\n",
      "**********************************************\n",
      "Epoch :  117\n",
      "Iteration :  0\n",
      "Loss :  -2402.670058867428\n",
      "**********************************************\n",
      "Epoch :  118\n",
      "Iteration :  0\n",
      "Loss :  -2401.332286004554\n",
      "**********************************************\n",
      "Epoch :  119\n",
      "Iteration :  0\n",
      "Loss :  -2392.313635263491\n",
      "**********************************************\n",
      "Epoch :  120\n",
      "Iteration :  0\n",
      "Loss :  -2396.144201278626\n",
      "**********************************************\n",
      "Epoch :  121\n",
      "Iteration :  0\n",
      "Loss :  -2399.1538797702583\n",
      "**********************************************\n",
      "Epoch :  122\n",
      "Iteration :  0\n",
      "Loss :  -2402.984804851176\n",
      "**********************************************\n",
      "Epoch :  123\n",
      "Iteration :  0\n",
      "Loss :  -2402.926395707268\n",
      "**********************************************\n",
      "Epoch :  124\n",
      "Iteration :  0\n",
      "Loss :  -2399.2410193302044\n",
      "**********************************************\n",
      "Epoch :  125\n",
      "Iteration :  0\n",
      "Loss :  -2396.583204687763\n",
      "**********************************************\n",
      "Epoch :  126\n",
      "Iteration :  0\n",
      "Loss :  -2391.4222134813567\n",
      "**********************************************\n",
      "Epoch :  127\n",
      "Iteration :  0\n",
      "Loss :  -2400.5437774624174\n",
      "**********************************************\n",
      "Epoch :  128\n",
      "Iteration :  0\n",
      "Loss :  -2404.9871329354623\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  129\n",
      "Iteration :  0\n",
      "Loss :  -2403.854044338134\n",
      "**********************************************\n",
      "Epoch :  130\n",
      "Iteration :  0\n",
      "Loss :  -2399.7529637214066\n",
      "**********************************************\n",
      "Epoch :  131\n",
      "Iteration :  0\n",
      "Loss :  -2390.753828147577\n",
      "**********************************************\n",
      "Epoch :  132\n",
      "Iteration :  0\n",
      "Loss :  -2392.2390854347686\n",
      "**********************************************\n",
      "Epoch :  133\n",
      "Iteration :  0\n",
      "Loss :  -2391.90586638584\n",
      "**********************************************\n",
      "Epoch :  134\n",
      "Iteration :  0\n",
      "Loss :  -2402.103190805752\n",
      "**********************************************\n",
      "Epoch :  135\n",
      "Iteration :  0\n",
      "Loss :  -2399.9974687610784\n",
      "**********************************************\n",
      "Epoch :  136\n",
      "Iteration :  0\n",
      "Loss :  -2387.878424289176\n",
      "**********************************************\n",
      "Epoch :  137\n",
      "Iteration :  0\n",
      "Loss :  -2393.2512982519797\n",
      "**********************************************\n",
      "Epoch :  138\n",
      "Iteration :  0\n",
      "Loss :  -2397.813456731866\n",
      "**********************************************\n",
      "Epoch :  139\n",
      "Iteration :  0\n",
      "Loss :  -2405.3387283157017\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  140\n",
      "Iteration :  0\n",
      "Loss :  -2400.3069471578688\n",
      "**********************************************\n",
      "Epoch :  141\n",
      "Iteration :  0\n",
      "Loss :  -2389.303055972973\n",
      "**********************************************\n",
      "Epoch :  142\n",
      "Iteration :  0\n",
      "Loss :  -2394.493721765071\n",
      "**********************************************\n",
      "Epoch :  143\n",
      "Iteration :  0\n",
      "Loss :  -2400.73726806297\n",
      "**********************************************\n",
      "Epoch :  144\n",
      "Iteration :  0\n",
      "Loss :  -2406.1396617959226\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  145\n",
      "Iteration :  0\n",
      "Loss :  -2401.3256120261995\n",
      "**********************************************\n",
      "Epoch :  146\n",
      "Iteration :  0\n",
      "Loss :  -2391.8442785355755\n",
      "**********************************************\n",
      "Epoch :  147\n",
      "Iteration :  0\n",
      "Loss :  -2396.3392295714634\n",
      "**********************************************\n",
      "Epoch :  148\n",
      "Iteration :  0\n",
      "Loss :  -2399.606901940168\n",
      "**********************************************\n",
      "Epoch :  149\n",
      "Iteration :  0\n",
      "Loss :  -2405.0733275517996\n",
      "**********************************************\n",
      "Epoch :  150\n",
      "Iteration :  0\n",
      "Loss :  -2402.3697763928626\n",
      "**********************************************\n",
      "Epoch :  151\n",
      "Iteration :  0\n",
      "Loss :  -2394.899782373753\n",
      "**********************************************\n",
      "Epoch :  152\n",
      "Iteration :  0\n",
      "Loss :  -2395.592999464579\n",
      "**********************************************\n",
      "Epoch :  153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :  0\n",
      "Loss :  -2396.0863146226993\n",
      "**********************************************\n",
      "Epoch :  154\n",
      "Iteration :  0\n",
      "Loss :  -2402.971596235425\n",
      "**********************************************\n",
      "Epoch :  155\n",
      "Iteration :  0\n",
      "Loss :  -2403.984427724682\n",
      "**********************************************\n",
      "Epoch :  156\n",
      "Iteration :  0\n",
      "Loss :  -2397.411475922551\n",
      "**********************************************\n",
      "Epoch :  157\n",
      "Iteration :  0\n",
      "Loss :  -2396.858924373881\n",
      "**********************************************\n",
      "Epoch :  158\n",
      "Iteration :  0\n",
      "Loss :  -2396.6549012565088\n",
      "**********************************************\n",
      "Epoch :  159\n",
      "Iteration :  0\n",
      "Loss :  -2406.824882618123\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  160\n",
      "Iteration :  0\n",
      "Loss :  -2407.3798111333886\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  161\n",
      "Iteration :  0\n",
      "Loss :  -2400.9844306049044\n",
      "**********************************************\n",
      "Epoch :  162\n",
      "Iteration :  0\n",
      "Loss :  -2398.754464699937\n",
      "**********************************************\n",
      "Epoch :  163\n",
      "Iteration :  0\n",
      "Loss :  -2395.8785906308626\n",
      "**********************************************\n",
      "Epoch :  164\n",
      "Iteration :  0\n",
      "Loss :  -2403.647140601133\n",
      "**********************************************\n",
      "Epoch :  165\n",
      "Iteration :  0\n",
      "Loss :  -2407.6476964467533\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  166\n",
      "Iteration :  0\n",
      "Loss :  -2407.296890938366\n",
      "**********************************************\n",
      "Epoch :  167\n",
      "Iteration :  0\n",
      "Loss :  -2402.4901393659848\n",
      "**********************************************\n",
      "Epoch :  168\n",
      "Iteration :  0\n",
      "Loss :  -2394.5781841696125\n",
      "**********************************************\n",
      "Epoch :  169\n",
      "Iteration :  0\n",
      "Loss :  -2398.044371583658\n",
      "**********************************************\n",
      "Epoch :  170\n",
      "Iteration :  0\n",
      "Loss :  -2400.271890909316\n",
      "**********************************************\n",
      "Epoch :  171\n",
      "Iteration :  0\n",
      "Loss :  -2407.9824250928896\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  172\n",
      "Iteration :  0\n",
      "Loss :  -2405.5670556964114\n",
      "**********************************************\n",
      "Epoch :  173\n",
      "Iteration :  0\n",
      "Loss :  -2396.755084537354\n",
      "**********************************************\n",
      "Epoch :  174\n",
      "Iteration :  0\n",
      "Loss :  -2396.3101942442486\n",
      "**********************************************\n",
      "Epoch :  175\n",
      "Iteration :  0\n",
      "Loss :  -2397.5519678772134\n",
      "**********************************************\n",
      "Epoch :  176\n",
      "Iteration :  0\n",
      "Loss :  -2408.056495451631\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  177\n",
      "Iteration :  0\n",
      "Loss :  -2406.340118656019\n",
      "**********************************************\n",
      "Epoch :  178\n",
      "Iteration :  0\n",
      "Loss :  -2395.5462703450785\n",
      "**********************************************\n",
      "Epoch :  179\n",
      "Iteration :  0\n",
      "Loss :  -2397.1682913268455\n",
      "**********************************************\n",
      "Epoch :  180\n",
      "Iteration :  0\n",
      "Loss :  -2398.57934397921\n",
      "**********************************************\n",
      "Epoch :  181\n",
      "Iteration :  0\n",
      "Loss :  -2406.561128697187\n",
      "**********************************************\n",
      "Epoch :  182\n",
      "Iteration :  0\n",
      "Loss :  -2405.1594167467256\n",
      "**********************************************\n",
      "Epoch :  183\n",
      "Iteration :  0\n",
      "Loss :  -2395.953248758684\n",
      "**********************************************\n",
      "Epoch :  184\n",
      "Iteration :  0\n",
      "Loss :  -2398.158357757728\n",
      "**********************************************\n",
      "Epoch :  185\n",
      "Iteration :  0\n",
      "Loss :  -2401.1957845802826\n",
      "**********************************************\n",
      "Epoch :  186\n",
      "Iteration :  0\n",
      "Loss :  -2408.829740624667\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  187\n",
      "Iteration :  0\n",
      "Loss :  -2406.0004091902474\n",
      "**********************************************\n",
      "Epoch :  188\n",
      "Iteration :  0\n",
      "Loss :  -2396.5961421822612\n",
      "**********************************************\n",
      "Epoch :  189\n",
      "Iteration :  0\n",
      "Loss :  -2399.049206405518\n",
      "**********************************************\n",
      "Epoch :  190\n",
      "Iteration :  0\n",
      "Loss :  -2401.784815286324\n",
      "**********************************************\n",
      "Epoch :  191\n",
      "Iteration :  0\n",
      "Loss :  -2408.5101073337905\n",
      "**********************************************\n",
      "Epoch :  192\n",
      "Iteration :  0\n",
      "Loss :  -2405.068153529359\n",
      "**********************************************\n",
      "Epoch :  193\n",
      "Iteration :  0\n",
      "Loss :  -2393.7103702501313\n",
      "**********************************************\n",
      "Epoch :  194\n",
      "Iteration :  0\n",
      "Loss :  -2398.6082127463847\n",
      "**********************************************\n",
      "Epoch :  195\n",
      "Iteration :  0\n",
      "Loss :  -2403.1669798379976\n",
      "**********************************************\n",
      "Epoch :  196\n",
      "Iteration :  0\n",
      "Loss :  -2409.201975682207\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  197\n",
      "Iteration :  0\n",
      "Loss :  -2403.5708344596364\n",
      "**********************************************\n",
      "Epoch :  198\n",
      "Iteration :  0\n",
      "Loss :  -2390.9623355362346\n",
      "**********************************************\n",
      "Epoch :  199\n",
      "Iteration :  0\n",
      "Loss :  -2397.9485010167673\n",
      "**********************************************\n",
      "Epoch :  200\n",
      "Iteration :  0\n",
      "Loss :  -2403.623088352371\n",
      "**********************************************\n",
      "Epoch :  201\n",
      "Iteration :  0\n",
      "Loss :  -2408.438880537026\n",
      "**********************************************\n",
      "Epoch :  202\n",
      "Iteration :  0\n",
      "Loss :  -2400.97857359238\n",
      "**********************************************\n",
      "Epoch :  203\n",
      "Iteration :  0\n",
      "Loss :  -2387.7051211748717\n",
      "**********************************************\n",
      "Epoch :  204\n",
      "Iteration :  0\n",
      "Loss :  -2399.3355323326414\n",
      "**********************************************\n",
      "Epoch :  205\n",
      "Iteration :  0\n",
      "Loss :  -2407.192512625651\n",
      "**********************************************\n",
      "Epoch :  206\n",
      "Iteration :  0\n",
      "Loss :  -2407.5172667165566\n",
      "**********************************************\n",
      "Epoch :  207\n",
      "Iteration :  0\n",
      "Loss :  -2402.233519745602\n",
      "**********************************************\n",
      "Epoch :  208\n",
      "Iteration :  0\n",
      "Loss :  -2395.10977462803\n",
      "**********************************************\n",
      "Epoch :  209\n",
      "Iteration :  0\n",
      "Loss :  -2402.4948471035073\n",
      "**********************************************\n",
      "Epoch :  210\n",
      "Iteration :  0\n",
      "Loss :  -2406.363555586709\n",
      "**********************************************\n",
      "Epoch :  211\n",
      "Iteration :  0\n",
      "Loss :  -2409.1954964502147\n",
      "**********************************************\n",
      "Epoch :  212\n",
      "Iteration :  0\n",
      "Loss :  -2405.9130509472384\n",
      "**********************************************\n",
      "Epoch :  213\n",
      "Iteration :  0\n",
      "Loss :  -2398.996494604855\n",
      "**********************************************\n",
      "Epoch :  214\n",
      "Iteration :  0\n",
      "Loss :  -2400.4411919139097\n",
      "**********************************************\n",
      "Epoch :  215\n",
      "Iteration :  0\n",
      "Loss :  -2401.06884741439\n",
      "**********************************************\n",
      "Epoch :  216\n",
      "Iteration :  0\n",
      "Loss :  -2408.043419852116\n",
      "**********************************************\n",
      "Epoch :  217\n",
      "Iteration :  0\n",
      "Loss :  -2408.6480908619674\n",
      "**********************************************\n",
      "Epoch :  218\n",
      "Iteration :  0\n",
      "Loss :  -2401.67966799394\n",
      "**********************************************\n",
      "Epoch :  219\n",
      "Iteration :  0\n",
      "Loss :  -2399.4392171034006\n",
      "**********************************************\n",
      "Epoch :  220\n",
      "Iteration :  0\n",
      "Loss :  -2397.2829740985603\n",
      "**********************************************\n",
      "Epoch :  221\n",
      "Iteration :  0\n",
      "Loss :  -2406.672138709057\n",
      "**********************************************\n",
      "Epoch :  222\n",
      "Iteration :  0\n",
      "Loss :  -2409.0395276420772\n",
      "**********************************************\n",
      "Epoch :  223\n",
      "Iteration :  0\n",
      "Loss :  -2404.3682252715025\n",
      "**********************************************\n",
      "Epoch :  224\n",
      "Iteration :  0\n",
      "Loss :  -2402.2080373384483\n",
      "**********************************************\n",
      "Epoch :  225\n",
      "Iteration :  0\n",
      "Loss :  -2400.1944785743412\n",
      "**********************************************\n",
      "Epoch :  226\n",
      "Iteration :  0\n",
      "Loss :  -2407.906281390298\n",
      "**********************************************\n",
      "Epoch :  227\n",
      "Iteration :  0\n",
      "Loss :  -2411.37065172608\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  228\n",
      "Iteration :  0\n",
      "Loss :  -2410.433874377253\n",
      "**********************************************\n",
      "Epoch :  229\n",
      "Iteration :  0\n",
      "Loss :  -2407.861248257491\n",
      "**********************************************\n",
      "Epoch :  230\n",
      "Iteration :  0\n",
      "Loss :  -2403.694230449845\n",
      "**********************************************\n",
      "Epoch :  231\n",
      "Iteration :  0\n",
      "Loss :  -2405.048505721203\n",
      "**********************************************\n",
      "Epoch :  232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :  0\n",
      "Loss :  -2402.897858328833\n",
      "**********************************************\n",
      "Epoch :  233\n",
      "Iteration :  0\n",
      "Loss :  -2409.368750100607\n",
      "**********************************************\n",
      "Epoch :  234\n",
      "Iteration :  0\n",
      "Loss :  -2411.6845806817637\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  235\n",
      "Iteration :  0\n",
      "Loss :  -2410.189285604762\n",
      "**********************************************\n",
      "Epoch :  236\n",
      "Iteration :  0\n",
      "Loss :  -2405.6997186412327\n",
      "**********************************************\n",
      "Epoch :  237\n",
      "Iteration :  0\n",
      "Loss :  -2398.275644206876\n",
      "**********************************************\n",
      "Epoch :  238\n",
      "Iteration :  0\n",
      "Loss :  -2401.74990409833\n",
      "**********************************************\n",
      "Epoch :  239\n",
      "Iteration :  0\n",
      "Loss :  -2405.3274486914543\n",
      "**********************************************\n",
      "Epoch :  240\n",
      "Iteration :  0\n",
      "Loss :  -2411.501954150549\n",
      "**********************************************\n",
      "Epoch :  241\n",
      "Iteration :  0\n",
      "Loss :  -2407.0758965715936\n",
      "**********************************************\n",
      "Epoch :  242\n",
      "Iteration :  0\n",
      "Loss :  -2394.7098963063636\n",
      "**********************************************\n",
      "Epoch :  243\n",
      "Iteration :  0\n",
      "Loss :  -2400.201812014798\n",
      "**********************************************\n",
      "Epoch :  244\n",
      "Iteration :  0\n",
      "Loss :  -2405.3464815877733\n",
      "**********************************************\n",
      "Epoch :  245\n",
      "Iteration :  0\n",
      "Loss :  -2411.9356467464395\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  246\n",
      "Iteration :  0\n",
      "Loss :  -2406.4740313861766\n",
      "**********************************************\n",
      "Epoch :  247\n",
      "Iteration :  0\n",
      "Loss :  -2390.885502624423\n",
      "**********************************************\n",
      "Epoch :  248\n",
      "Iteration :  0\n",
      "Loss :  -2399.417738427347\n",
      "**********************************************\n",
      "Epoch :  249\n",
      "Iteration :  0\n",
      "Loss :  -2406.5987467672444\n",
      "**********************************************\n",
      "Epoch :  250\n",
      "Iteration :  0\n",
      "Loss :  -2409.5922444787484\n",
      "**********************************************\n",
      "Epoch :  251\n",
      "Iteration :  0\n",
      "Loss :  -2402.5241399279494\n",
      "**********************************************\n",
      "Epoch :  252\n",
      "Iteration :  0\n",
      "Loss :  -2393.1117219468115\n",
      "**********************************************\n",
      "Epoch :  253\n",
      "Iteration :  0\n",
      "Loss :  -2403.005659928862\n",
      "**********************************************\n",
      "Epoch :  254\n",
      "Iteration :  0\n",
      "Loss :  -2409.5442068012107\n",
      "**********************************************\n",
      "Epoch :  255\n",
      "Iteration :  0\n",
      "Loss :  -2408.721951873241\n",
      "**********************************************\n",
      "Epoch :  256\n",
      "Iteration :  0\n",
      "Loss :  -2404.5189616657667\n",
      "**********************************************\n",
      "Epoch :  257\n",
      "Iteration :  0\n",
      "Loss :  -2398.437299346952\n",
      "**********************************************\n",
      "Epoch :  258\n",
      "Iteration :  0\n",
      "Loss :  -2404.046871166508\n",
      "**********************************************\n",
      "Epoch :  259\n",
      "Iteration :  0\n",
      "Loss :  -2407.542025284097\n",
      "**********************************************\n",
      "Epoch :  260\n",
      "Iteration :  0\n",
      "Loss :  -2410.9912748458137\n",
      "**********************************************\n",
      "Epoch :  261\n",
      "Iteration :  0\n",
      "Loss :  -2408.838377927116\n",
      "**********************************************\n",
      "Epoch :  262\n",
      "Iteration :  0\n",
      "Loss :  -2403.7685659005638\n",
      "**********************************************\n",
      "Epoch :  263\n",
      "Iteration :  0\n",
      "Loss :  -2402.6578754414913\n",
      "**********************************************\n",
      "Epoch :  264\n",
      "Iteration :  0\n",
      "Loss :  -2401.0791942558103\n",
      "**********************************************\n",
      "Epoch :  265\n",
      "Iteration :  0\n",
      "Loss :  -2409.5494535721514\n",
      "**********************************************\n",
      "Epoch :  266\n",
      "Iteration :  0\n",
      "Loss :  -2411.1705484233853\n",
      "**********************************************\n",
      "Epoch :  267\n",
      "Iteration :  0\n",
      "Loss :  -2405.270947779092\n",
      "**********************************************\n",
      "Epoch :  268\n",
      "Iteration :  0\n",
      "Loss :  -2404.1728312699524\n",
      "**********************************************\n",
      "Epoch :  269\n",
      "Iteration :  0\n",
      "Loss :  -2402.565813952681\n",
      "**********************************************\n",
      "Epoch :  270\n",
      "Iteration :  0\n",
      "Loss :  -2411.135077869555\n",
      "**********************************************\n",
      "Epoch :  271\n",
      "Iteration :  0\n",
      "Loss :  -2411.9634750737996\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  272\n",
      "Iteration :  0\n",
      "Loss :  -2410.0493300049607\n",
      "**********************************************\n",
      "Epoch :  273\n",
      "Iteration :  0\n",
      "Loss :  -2406.967426422914\n",
      "**********************************************\n",
      "Epoch :  274\n",
      "Iteration :  0\n",
      "Loss :  -2401.6219402442384\n",
      "**********************************************\n",
      "Epoch :  275\n",
      "Iteration :  0\n",
      "Loss :  -2409.0282036109634\n",
      "**********************************************\n",
      "Epoch :  276\n",
      "Iteration :  0\n",
      "Loss :  -2413.3068965416796\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  277\n",
      "Iteration :  0\n",
      "Loss :  -2413.8680031539016\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  278\n",
      "Iteration :  0\n",
      "Loss :  -2411.4507280735684\n",
      "**********************************************\n",
      "Epoch :  279\n",
      "Iteration :  0\n",
      "Loss :  -2406.517475626761\n",
      "**********************************************\n",
      "Epoch :  280\n",
      "Iteration :  0\n",
      "Loss :  -2405.550813950502\n",
      "**********************************************\n",
      "Epoch :  281\n",
      "Iteration :  0\n",
      "Loss :  -2404.0456131459327\n",
      "**********************************************\n",
      "Epoch :  282\n",
      "Iteration :  0\n",
      "Loss :  -2410.511300146913\n",
      "**********************************************\n",
      "Epoch :  283\n",
      "Iteration :  0\n",
      "Loss :  -2413.2697088201635\n",
      "**********************************************\n",
      "Epoch :  284\n",
      "Iteration :  0\n",
      "Loss :  -2411.3508973774856\n",
      "**********************************************\n",
      "Epoch :  285\n",
      "Iteration :  0\n",
      "Loss :  -2408.3792571755234\n",
      "**********************************************\n",
      "Epoch :  286\n",
      "Iteration :  0\n",
      "Loss :  -2399.8083056427054\n",
      "**********************************************\n",
      "Epoch :  287\n",
      "Iteration :  0\n",
      "Loss :  -2403.5182185997865\n",
      "**********************************************\n",
      "Epoch :  288\n",
      "Iteration :  0\n",
      "Loss :  -2409.728630104978\n",
      "**********************************************\n",
      "Epoch :  289\n",
      "Iteration :  0\n",
      "Loss :  -2414.1787765983977\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  290\n",
      "Iteration :  0\n",
      "Loss :  -2409.8401961211734\n",
      "**********************************************\n",
      "Epoch :  291\n",
      "Iteration :  0\n",
      "Loss :  -2401.981917666681\n",
      "**********************************************\n",
      "Epoch :  292\n",
      "Iteration :  0\n",
      "Loss :  -2403.8882324355527\n",
      "**********************************************\n",
      "Epoch :  293\n",
      "Iteration :  0\n",
      "Loss :  -2406.4553488267334\n",
      "**********************************************\n",
      "Epoch :  294\n",
      "Iteration :  0\n",
      "Loss :  -2413.6627591942215\n",
      "**********************************************\n",
      "Epoch :  295\n",
      "Iteration :  0\n",
      "Loss :  -2410.2263215702137\n",
      "**********************************************\n",
      "Epoch :  296\n",
      "Iteration :  0\n",
      "Loss :  -2400.3270758586104\n",
      "**********************************************\n",
      "Epoch :  297\n",
      "Iteration :  0\n",
      "Loss :  -2403.3767010140027\n",
      "**********************************************\n",
      "Epoch :  298\n",
      "Iteration :  0\n",
      "Loss :  -2406.6107110502485\n",
      "**********************************************\n",
      "Epoch :  299\n",
      "Iteration :  0\n",
      "Loss :  -2412.9466252344446\n",
      "**********************************************\n",
      "Epoch :  300\n",
      "Iteration :  0\n",
      "Loss :  -2407.8373725763827\n",
      "**********************************************\n",
      "Epoch :  301\n",
      "Iteration :  0\n",
      "Loss :  -2394.7413770287103\n",
      "**********************************************\n",
      "Epoch :  302\n",
      "Iteration :  0\n",
      "Loss :  -2403.427749855783\n",
      "**********************************************\n",
      "Epoch :  303\n",
      "Iteration :  0\n",
      "Loss :  -2409.7303649246765\n",
      "**********************************************\n",
      "Epoch :  304\n",
      "Iteration :  0\n",
      "Loss :  -2410.4894586237074\n",
      "**********************************************\n",
      "Epoch :  305\n",
      "Iteration :  0\n",
      "Loss :  -2405.5939457804257\n",
      "**********************************************\n",
      "Epoch :  306\n",
      "Iteration :  0\n",
      "Loss :  -2398.183787368358\n",
      "**********************************************\n",
      "Epoch :  307\n",
      "Iteration :  0\n",
      "Loss :  -2404.725096115267\n",
      "**********************************************\n",
      "Epoch :  308\n",
      "Iteration :  0\n",
      "Loss :  -2409.6513680717912\n",
      "**********************************************\n",
      "Epoch :  309\n",
      "Iteration :  0\n",
      "Loss :  -2412.039325603633\n",
      "**********************************************\n",
      "Epoch :  310\n",
      "Iteration :  0\n",
      "Loss :  -2409.7958973205755\n",
      "**********************************************\n",
      "Epoch :  311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :  0\n",
      "Loss :  -2405.282194845315\n",
      "**********************************************\n",
      "Epoch :  312\n",
      "Iteration :  0\n",
      "Loss :  -2403.811359118505\n",
      "**********************************************\n",
      "Epoch :  313\n",
      "Iteration :  0\n",
      "Loss :  -2404.7955159792805\n",
      "**********************************************\n",
      "Epoch :  314\n",
      "Iteration :  0\n",
      "Loss :  -2409.1537115195233\n",
      "**********************************************\n",
      "Epoch :  315\n",
      "Iteration :  0\n",
      "Loss :  -2410.9521668149396\n",
      "**********************************************\n",
      "Epoch :  316\n",
      "Iteration :  0\n",
      "Loss :  -2409.4817146675578\n",
      "**********************************************\n",
      "Epoch :  317\n",
      "Iteration :  0\n",
      "Loss :  -2408.8368101801657\n",
      "**********************************************\n",
      "Epoch :  318\n",
      "Iteration :  0\n",
      "Loss :  -2403.1013407322075\n",
      "**********************************************\n",
      "Epoch :  319\n",
      "Iteration :  0\n",
      "Loss :  -2402.412902783254\n",
      "**********************************************\n",
      "Epoch :  320\n",
      "Iteration :  0\n",
      "Loss :  -2409.6663097246987\n",
      "**********************************************\n",
      "Epoch :  321\n",
      "Iteration :  0\n",
      "Loss :  -2412.983204392171\n",
      "**********************************************\n",
      "Epoch :  322\n",
      "Iteration :  0\n",
      "Loss :  -2412.5352790345733\n",
      "**********************************************\n",
      "Epoch :  323\n",
      "Iteration :  0\n",
      "Loss :  -2410.2294033142903\n",
      "**********************************************\n",
      "Epoch :  324\n",
      "Iteration :  0\n",
      "Loss :  -2408.5087224669624\n",
      "**********************************************\n",
      "Epoch :  325\n",
      "Iteration :  0\n",
      "Loss :  -2403.8149753959215\n",
      "**********************************************\n",
      "Epoch :  326\n",
      "Iteration :  0\n",
      "Loss :  -2406.868495282912\n",
      "**********************************************\n",
      "Epoch :  327\n",
      "Iteration :  0\n",
      "Loss :  -2410.36488614546\n",
      "**********************************************\n",
      "Epoch :  328\n",
      "Iteration :  0\n",
      "Loss :  -2413.2760160676658\n",
      "**********************************************\n",
      "Epoch :  329\n",
      "Iteration :  0\n",
      "Loss :  -2414.0924441176167\n",
      "**********************************************\n",
      "Epoch :  330\n",
      "Iteration :  0\n",
      "Loss :  -2409.297693505666\n",
      "**********************************************\n",
      "Epoch :  331\n",
      "Iteration :  0\n",
      "Loss :  -2406.776360820178\n",
      "**********************************************\n",
      "Epoch :  332\n",
      "Iteration :  0\n",
      "Loss :  -2401.792491553179\n",
      "**********************************************\n",
      "Epoch :  333\n",
      "Iteration :  0\n",
      "Loss :  -2409.0599967818457\n",
      "**********************************************\n",
      "Epoch :  334\n",
      "Iteration :  0\n",
      "Loss :  -2414.974628593239\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  335\n",
      "Iteration :  0\n",
      "Loss :  -2413.3948797542907\n",
      "**********************************************\n",
      "Epoch :  336\n",
      "Iteration :  0\n",
      "Loss :  -2410.1055729766604\n",
      "**********************************************\n",
      "Epoch :  337\n",
      "Iteration :  0\n",
      "Loss :  -2404.3374941735465\n",
      "**********************************************\n",
      "Epoch :  338\n",
      "Iteration :  0\n",
      "Loss :  -2406.0420586750893\n",
      "**********************************************\n",
      "Epoch :  339\n",
      "Iteration :  0\n",
      "Loss :  -2409.5517411333567\n",
      "**********************************************\n",
      "Epoch :  340\n",
      "Iteration :  0\n",
      "Loss :  -2414.891342457389\n",
      "**********************************************\n",
      "Epoch :  341\n",
      "Iteration :  0\n",
      "Loss :  -2415.0740170571394\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  342\n",
      "Iteration :  0\n",
      "Loss :  -2408.026113760482\n",
      "**********************************************\n",
      "Epoch :  343\n",
      "Iteration :  0\n",
      "Loss :  -2405.719633652265\n",
      "**********************************************\n",
      "Epoch :  344\n",
      "Iteration :  0\n",
      "Loss :  -2403.5796771102678\n",
      "**********************************************\n",
      "Epoch :  345\n",
      "Iteration :  0\n",
      "Loss :  -2412.3104874929054\n",
      "**********************************************\n",
      "Epoch :  346\n",
      "Iteration :  0\n",
      "Loss :  -2413.8242529889462\n",
      "**********************************************\n",
      "Epoch :  347\n",
      "Iteration :  0\n",
      "Loss :  -2407.3691829321474\n",
      "**********************************************\n",
      "Epoch :  348\n",
      "Iteration :  0\n",
      "Loss :  -2406.28955067562\n",
      "**********************************************\n",
      "Epoch :  349\n",
      "Iteration :  0\n",
      "Loss :  -2403.5182265626804\n",
      "**********************************************\n",
      "Epoch :  350\n",
      "Iteration :  0\n",
      "Loss :  -2413.14388837225\n",
      "**********************************************\n",
      "Epoch :  351\n",
      "Iteration :  0\n",
      "Loss :  -2414.668034020837\n",
      "**********************************************\n",
      "Epoch :  352\n",
      "Iteration :  0\n",
      "Loss :  -2408.179209534769\n",
      "**********************************************\n",
      "Epoch :  353\n",
      "Iteration :  0\n",
      "Loss :  -2408.5357198200672\n",
      "**********************************************\n",
      "Epoch :  354\n",
      "Iteration :  0\n",
      "Loss :  -2409.1268193048854\n",
      "**********************************************\n",
      "Epoch :  355\n",
      "Iteration :  0\n",
      "Loss :  -2415.1405079285732\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  356\n",
      "Iteration :  0\n",
      "Loss :  -2415.5859735752856\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  357\n",
      "Iteration :  0\n",
      "Loss :  -2411.688472520648\n",
      "**********************************************\n",
      "Epoch :  358\n",
      "Iteration :  0\n",
      "Loss :  -2409.677507507017\n",
      "**********************************************\n",
      "Epoch :  359\n",
      "Iteration :  0\n",
      "Loss :  -2406.4801828547897\n",
      "**********************************************\n",
      "Epoch :  360\n",
      "Iteration :  0\n",
      "Loss :  -2412.7947469081155\n",
      "**********************************************\n",
      "Epoch :  361\n",
      "Iteration :  0\n",
      "Loss :  -2416.6314431046458\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  362\n",
      "Iteration :  0\n",
      "Loss :  -2416.08762685896\n",
      "**********************************************\n",
      "Epoch :  363\n",
      "Iteration :  0\n",
      "Loss :  -2413.420946690124\n",
      "**********************************************\n",
      "Epoch :  364\n",
      "Iteration :  0\n",
      "Loss :  -2408.6080727210892\n",
      "**********************************************\n",
      "Epoch :  365\n",
      "Iteration :  0\n",
      "Loss :  -2409.1243502734283\n",
      "**********************************************\n",
      "Epoch :  366\n",
      "Iteration :  0\n",
      "Loss :  -2409.610629170498\n",
      "**********************************************\n",
      "Epoch :  367\n",
      "Iteration :  0\n",
      "Loss :  -2415.450474769918\n",
      "**********************************************\n",
      "Epoch :  368\n",
      "Iteration :  0\n",
      "Loss :  -2416.576141188508\n",
      "**********************************************\n",
      "Epoch :  369\n",
      "Iteration :  0\n",
      "Loss :  -2412.6213795202107\n",
      "**********************************************\n",
      "Epoch :  370\n",
      "Iteration :  0\n",
      "Loss :  -2409.440975400513\n",
      "**********************************************\n",
      "Epoch :  371\n",
      "Iteration :  0\n",
      "Loss :  -2405.7335675150034\n",
      "**********************************************\n",
      "Epoch :  372\n",
      "Iteration :  0\n",
      "Loss :  -2412.249627788812\n",
      "**********************************************\n",
      "Epoch :  373\n",
      "Iteration :  0\n",
      "Loss :  -2416.4653571280433\n",
      "**********************************************\n",
      "Epoch :  374\n",
      "Iteration :  0\n",
      "Loss :  -2415.7737361670097\n",
      "**********************************************\n",
      "Epoch :  375\n",
      "Iteration :  0\n",
      "Loss :  -2412.3559274627214\n",
      "**********************************************\n",
      "Epoch :  376\n",
      "Iteration :  0\n",
      "Loss :  -2406.421044303788\n",
      "**********************************************\n",
      "Epoch :  377\n",
      "Iteration :  0\n",
      "Loss :  -2408.171359926753\n",
      "**********************************************\n",
      "Epoch :  378\n",
      "Iteration :  0\n",
      "Loss :  -2411.1789194082407\n",
      "**********************************************\n",
      "Epoch :  379\n",
      "Iteration :  0\n",
      "Loss :  -2415.323996370031\n",
      "**********************************************\n",
      "Epoch :  380\n",
      "Iteration :  0\n",
      "Loss :  -2414.325916410578\n",
      "**********************************************\n",
      "Epoch :  381\n",
      "Iteration :  0\n",
      "Loss :  -2409.823220363581\n",
      "**********************************************\n",
      "Epoch :  382\n",
      "Iteration :  0\n",
      "Loss :  -2407.66089461732\n",
      "**********************************************\n",
      "Epoch :  383\n",
      "Iteration :  0\n",
      "Loss :  -2405.8969975699442\n",
      "**********************************************\n",
      "Epoch :  384\n",
      "Iteration :  0\n",
      "Loss :  -2412.446188448794\n",
      "**********************************************\n",
      "Epoch :  385\n",
      "Iteration :  0\n",
      "Loss :  -2414.129693728791\n",
      "**********************************************\n",
      "Epoch :  386\n",
      "Iteration :  0\n",
      "Loss :  -2411.5373043121535\n",
      "**********************************************\n",
      "Epoch :  387\n",
      "Iteration :  0\n",
      "Loss :  -2410.0337050606954\n",
      "**********************************************\n",
      "Epoch :  388\n",
      "Iteration :  0\n",
      "Loss :  -2406.34806746732\n",
      "**********************************************\n",
      "Epoch :  389\n",
      "Iteration :  0\n",
      "Loss :  -2408.1492174759933\n",
      "**********************************************\n",
      "Epoch :  390\n",
      "Iteration :  0\n",
      "Loss :  -2411.531190593319\n",
      "**********************************************\n",
      "Epoch :  391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :  0\n",
      "Loss :  -2414.370627242619\n",
      "**********************************************\n",
      "Epoch :  392\n",
      "Iteration :  0\n",
      "Loss :  -2413.629203381564\n",
      "**********************************************\n",
      "Epoch :  393\n",
      "Iteration :  0\n",
      "Loss :  -2409.59085318776\n",
      "**********************************************\n",
      "Epoch :  394\n",
      "Iteration :  0\n",
      "Loss :  -2407.0092954492543\n",
      "**********************************************\n",
      "Epoch :  395\n",
      "Iteration :  0\n",
      "Loss :  -2403.302617078084\n",
      "**********************************************\n",
      "Epoch :  396\n",
      "Iteration :  0\n",
      "Loss :  -2410.7942671906717\n",
      "**********************************************\n",
      "Epoch :  397\n",
      "Iteration :  0\n",
      "Loss :  -2415.090264400056\n",
      "**********************************************\n",
      "Epoch :  398\n",
      "Iteration :  0\n",
      "Loss :  -2411.947394194756\n",
      "**********************************************\n",
      "Epoch :  399\n",
      "Iteration :  0\n",
      "Loss :  -2408.0828529920695\n",
      "**********************************************\n",
      "Epoch :  400\n",
      "Iteration :  0\n",
      "Loss :  -2403.2518873691934\n",
      "**********************************************\n",
      "Epoch :  401\n",
      "Iteration :  0\n",
      "Loss :  -2407.9901806954817\n",
      "**********************************************\n",
      "Epoch :  402\n",
      "Iteration :  0\n",
      "Loss :  -2412.314039571268\n",
      "**********************************************\n",
      "Epoch :  403\n",
      "Iteration :  0\n",
      "Loss :  -2414.455334290264\n",
      "**********************************************\n",
      "Epoch :  404\n",
      "Iteration :  0\n",
      "Loss :  -2413.4785451654943\n",
      "**********************************************\n",
      "Epoch :  405\n",
      "Iteration :  0\n",
      "Loss :  -2410.349093987228\n",
      "**********************************************\n",
      "Epoch :  406\n",
      "Iteration :  0\n",
      "Loss :  -2407.6415429160584\n",
      "**********************************************\n",
      "Epoch :  407\n",
      "Iteration :  0\n",
      "Loss :  -2403.4813892813286\n",
      "**********************************************\n",
      "Epoch :  408\n",
      "Iteration :  0\n",
      "Loss :  -2410.42419698676\n",
      "**********************************************\n",
      "Epoch :  409\n",
      "Iteration :  0\n",
      "Loss :  -2415.9489875459726\n",
      "**********************************************\n",
      "Epoch :  410\n",
      "Iteration :  0\n",
      "Loss :  -2413.5201421376837\n",
      "**********************************************\n",
      "Epoch :  411\n",
      "Iteration :  0\n",
      "Loss :  -2410.0600390912414\n",
      "**********************************************\n",
      "Epoch :  412\n",
      "Iteration :  0\n",
      "Loss :  -2405.9349607952827\n",
      "**********************************************\n",
      "Epoch :  413\n",
      "Iteration :  0\n",
      "Loss :  -2407.354264229333\n",
      "**********************************************\n",
      "Epoch :  414\n",
      "Iteration :  0\n",
      "Loss :  -2410.341910898949\n",
      "**********************************************\n",
      "Epoch :  415\n",
      "Iteration :  0\n",
      "Loss :  -2415.2171273443714\n",
      "**********************************************\n",
      "Epoch :  416\n",
      "Iteration :  0\n",
      "Loss :  -2415.425307221236\n",
      "**********************************************\n",
      "Epoch :  417\n",
      "Iteration :  0\n",
      "Loss :  -2411.437248205656\n",
      "**********************************************\n",
      "Epoch :  418\n",
      "Iteration :  0\n",
      "Loss :  -2408.885825236733\n",
      "**********************************************\n",
      "Epoch :  419\n",
      "Iteration :  0\n",
      "Loss :  -2403.474454962963\n",
      "**********************************************\n",
      "Epoch :  420\n",
      "Iteration :  0\n",
      "Loss :  -2410.1401487223816\n",
      "**********************************************\n",
      "Epoch :  421\n",
      "Iteration :  0\n",
      "Loss :  -2416.3650755159524\n",
      "**********************************************\n",
      "Epoch :  422\n",
      "Iteration :  0\n",
      "Loss :  -2414.832421940789\n",
      "**********************************************\n",
      "Epoch :  423\n",
      "Iteration :  0\n",
      "Loss :  -2410.337809045884\n",
      "**********************************************\n",
      "Epoch :  424\n",
      "Iteration :  0\n",
      "Loss :  -2404.0519501322738\n",
      "**********************************************\n",
      "Epoch :  425\n",
      "Iteration :  0\n",
      "Loss :  -2408.1032569713225\n",
      "**********************************************\n",
      "Epoch :  426\n",
      "Iteration :  0\n",
      "Loss :  -2411.9930475642964\n",
      "**********************************************\n",
      "Epoch :  427\n",
      "Iteration :  0\n",
      "Loss :  -2415.157918798723\n",
      "**********************************************\n",
      "Epoch :  428\n",
      "Iteration :  0\n",
      "Loss :  -2414.106110471185\n",
      "**********************************************\n",
      "Epoch :  429\n",
      "Iteration :  0\n",
      "Loss :  -2408.1169176085436\n",
      "**********************************************\n",
      "Epoch :  430\n",
      "Iteration :  0\n",
      "Loss :  -2406.89791989625\n",
      "**********************************************\n",
      "Epoch :  431\n",
      "Iteration :  0\n",
      "Loss :  -2405.791041690826\n",
      "**********************************************\n",
      "Epoch :  432\n",
      "Iteration :  0\n",
      "Loss :  -2413.8355852105947\n",
      "**********************************************\n",
      "Epoch :  433\n",
      "Iteration :  0\n",
      "Loss :  -2414.9735973457655\n",
      "**********************************************\n",
      "Epoch :  434\n",
      "Iteration :  0\n",
      "Loss :  -2408.082288337335\n",
      "**********************************************\n",
      "Epoch :  435\n",
      "Iteration :  0\n",
      "Loss :  -2406.0654218004447\n",
      "**********************************************\n",
      "Epoch :  436\n",
      "Iteration :  0\n",
      "Loss :  -2404.1634035043053\n",
      "**********************************************\n",
      "Epoch :  437\n",
      "Iteration :  0\n",
      "Loss :  -2414.4932399107706\n",
      "**********************************************\n",
      "Epoch :  438\n",
      "Iteration :  0\n",
      "Loss :  -2414.7372835376\n",
      "**********************************************\n",
      "Epoch :  439\n",
      "Iteration :  0\n",
      "Loss :  -2405.6064257985595\n",
      "**********************************************\n",
      "Epoch :  440\n",
      "Iteration :  0\n",
      "Loss :  -2407.2361921261627\n",
      "**********************************************\n",
      "Epoch :  441\n",
      "Iteration :  0\n",
      "Loss :  -2409.405647723137\n",
      "**********************************************\n",
      "Epoch :  442\n",
      "Iteration :  0\n",
      "Loss :  -2416.5630138240176\n",
      "**********************************************\n",
      "Epoch :  443\n",
      "Iteration :  0\n",
      "Loss :  -2413.850204095324\n",
      "**********************************************\n",
      "Epoch :  444\n",
      "Iteration :  0\n",
      "Loss :  -2405.2850529458196\n",
      "**********************************************\n",
      "Epoch :  445\n",
      "Iteration :  0\n",
      "Loss :  -2408.1071159244016\n",
      "**********************************************\n",
      "Epoch :  446\n",
      "Iteration :  0\n",
      "Loss :  -2411.5042437921948\n",
      "**********************************************\n",
      "Epoch :  447\n",
      "Iteration :  0\n",
      "Loss :  -2416.7296195072563\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  448\n",
      "Iteration :  0\n",
      "Loss :  -2412.970264655342\n",
      "**********************************************\n",
      "Epoch :  449\n",
      "Iteration :  0\n",
      "Loss :  -2403.918386909663\n",
      "**********************************************\n",
      "Epoch :  450\n",
      "Iteration :  0\n",
      "Loss :  -2407.629821554472\n",
      "**********************************************\n",
      "Epoch :  451\n",
      "Iteration :  0\n",
      "Loss :  -2411.5079022704067\n",
      "**********************************************\n",
      "Epoch :  452\n",
      "Iteration :  0\n",
      "Loss :  -2416.6279217244446\n",
      "**********************************************\n",
      "Epoch :  453\n",
      "Iteration :  0\n",
      "Loss :  -2412.040804839677\n",
      "**********************************************\n",
      "Epoch :  454\n",
      "Iteration :  0\n",
      "Loss :  -2403.1773266500336\n",
      "**********************************************\n",
      "Epoch :  455\n",
      "Iteration :  0\n",
      "Loss :  -2407.0267607977703\n",
      "**********************************************\n",
      "Epoch :  456\n",
      "Iteration :  0\n",
      "Loss :  -2410.702290376885\n",
      "**********************************************\n",
      "Epoch :  457\n",
      "Iteration :  0\n",
      "Loss :  -2416.5613129905573\n",
      "**********************************************\n",
      "Epoch :  458\n",
      "Iteration :  0\n",
      "Loss :  -2411.1109284233935\n",
      "**********************************************\n",
      "Epoch :  459\n",
      "Iteration :  0\n",
      "Loss :  -2401.297767006361\n",
      "**********************************************\n",
      "Epoch :  460\n",
      "Iteration :  0\n",
      "Loss :  -2407.4920554299447\n",
      "**********************************************\n",
      "Epoch :  461\n",
      "Iteration :  0\n",
      "Loss :  -2411.416547332464\n",
      "**********************************************\n",
      "Epoch :  462\n",
      "Iteration :  0\n",
      "Loss :  -2415.8849990566364\n",
      "**********************************************\n",
      "Epoch :  463\n",
      "Iteration :  0\n",
      "Loss :  -2410.035683640552\n",
      "**********************************************\n",
      "Epoch :  464\n",
      "Iteration :  0\n",
      "Loss :  -2400.852554487343\n",
      "**********************************************\n",
      "Epoch :  465\n",
      "Iteration :  0\n",
      "Loss :  -2408.5806896514523\n",
      "**********************************************\n",
      "Epoch :  466\n",
      "Iteration :  0\n",
      "Loss :  -2412.4594959543087\n",
      "**********************************************\n",
      "Epoch :  467\n",
      "Iteration :  0\n",
      "Loss :  -2415.060786258209\n",
      "**********************************************\n",
      "Epoch :  468\n",
      "Iteration :  0\n",
      "Loss :  -2410.0635977636452\n",
      "**********************************************\n",
      "Epoch :  469\n",
      "Iteration :  0\n",
      "Loss :  -2402.6616690717124\n",
      "**********************************************\n",
      "Epoch :  470\n",
      "Iteration :  0\n",
      "Loss :  -2408.708193624282\n",
      "**********************************************\n",
      "Epoch :  471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :  0\n",
      "Loss :  -2411.78561341305\n",
      "**********************************************\n",
      "Epoch :  472\n",
      "Iteration :  0\n",
      "Loss :  -2414.905287262835\n",
      "**********************************************\n",
      "Epoch :  473\n",
      "Iteration :  0\n",
      "Loss :  -2412.193471068347\n",
      "**********************************************\n",
      "Epoch :  474\n",
      "Iteration :  0\n",
      "Loss :  -2405.7291274722147\n",
      "**********************************************\n",
      "Epoch :  475\n",
      "Iteration :  0\n",
      "Loss :  -2407.2897857162043\n",
      "**********************************************\n",
      "Epoch :  476\n",
      "Iteration :  0\n",
      "Loss :  -2408.9115460119333\n",
      "**********************************************\n",
      "Epoch :  477\n",
      "Iteration :  0\n",
      "Loss :  -2416.1738206434015\n",
      "**********************************************\n",
      "Epoch :  478\n",
      "Iteration :  0\n",
      "Loss :  -2413.606631757228\n",
      "**********************************************\n",
      "Epoch :  479\n",
      "Iteration :  0\n",
      "Loss :  -2406.5935956946396\n",
      "**********************************************\n",
      "Epoch :  480\n",
      "Iteration :  0\n",
      "Loss :  -2407.462838942418\n",
      "**********************************************\n",
      "Epoch :  481\n",
      "Iteration :  0\n",
      "Loss :  -2407.7073421920477\n",
      "**********************************************\n",
      "Epoch :  482\n",
      "Iteration :  0\n",
      "Loss :  -2415.8207722381503\n",
      "**********************************************\n",
      "Epoch :  483\n",
      "Iteration :  0\n",
      "Loss :  -2413.8457644913037\n",
      "**********************************************\n",
      "Epoch :  484\n",
      "Iteration :  0\n",
      "Loss :  -2405.7675704978747\n",
      "**********************************************\n",
      "Epoch :  485\n",
      "Iteration :  0\n",
      "Loss :  -2407.1584127731567\n",
      "**********************************************\n",
      "Epoch :  486\n",
      "Iteration :  0\n",
      "Loss :  -2409.3878091040788\n",
      "**********************************************\n",
      "Epoch :  487\n",
      "Iteration :  0\n",
      "Loss :  -2416.0011805994704\n",
      "**********************************************\n",
      "Epoch :  488\n",
      "Iteration :  0\n",
      "Loss :  -2412.1296920490777\n",
      "**********************************************\n",
      "Epoch :  489\n",
      "Iteration :  0\n",
      "Loss :  -2405.7189071801204\n",
      "**********************************************\n",
      "Epoch :  490\n",
      "Iteration :  0\n",
      "Loss :  -2408.5744404287234\n",
      "**********************************************\n",
      "Epoch :  491\n",
      "Iteration :  0\n",
      "Loss :  -2410.254718897445\n",
      "**********************************************\n",
      "Epoch :  492\n",
      "Iteration :  0\n",
      "Loss :  -2414.5254360077115\n",
      "**********************************************\n",
      "Epoch :  493\n",
      "Iteration :  0\n",
      "Loss :  -2413.1181154559767\n",
      "**********************************************\n",
      "Epoch :  494\n",
      "Iteration :  0\n",
      "Loss :  -2409.4993351872913\n",
      "**********************************************\n",
      "Epoch :  495\n",
      "Iteration :  0\n",
      "Loss :  -2409.11971741907\n",
      "**********************************************\n",
      "Epoch :  496\n",
      "Iteration :  0\n",
      "Loss :  -2408.4073925728817\n",
      "**********************************************\n",
      "Epoch :  497\n",
      "Iteration :  0\n",
      "Loss :  -2413.240036838894\n",
      "**********************************************\n",
      "Epoch :  498\n",
      "Iteration :  0\n",
      "Loss :  -2414.3122441328046\n",
      "**********************************************\n",
      "Epoch :  499\n",
      "Iteration :  0\n",
      "Loss :  -2413.3418701000824\n",
      "**********************************************\n",
      "Epoch :  500\n",
      "Iteration :  0\n",
      "Loss :  -2410.142288185902\n",
      "**********************************************\n",
      "Epoch :  501\n",
      "Iteration :  0\n",
      "Loss :  -2405.0019579239906\n",
      "**********************************************\n",
      "Epoch :  502\n",
      "Iteration :  0\n",
      "Loss :  -2411.8495736166014\n",
      "**********************************************\n",
      "Epoch :  503\n",
      "Iteration :  0\n",
      "Loss :  -2415.7999215713858\n",
      "**********************************************\n",
      "Epoch :  504\n",
      "Iteration :  0\n",
      "Loss :  -2416.241080219234\n",
      "**********************************************\n",
      "Epoch :  505\n",
      "Iteration :  0\n",
      "Loss :  -2413.7273471365506\n",
      "**********************************************\n",
      "Epoch :  506\n",
      "Iteration :  0\n",
      "Loss :  -2410.1323298850775\n",
      "**********************************************\n",
      "Epoch :  507\n",
      "Iteration :  0\n",
      "Loss :  -2410.4339882627282\n",
      "**********************************************\n",
      "Epoch :  508\n",
      "Iteration :  0\n",
      "Loss :  -2409.755977358701\n",
      "**********************************************\n",
      "Epoch :  509\n",
      "Iteration :  0\n",
      "Loss :  -2414.1956511924623\n",
      "**********************************************\n",
      "Epoch :  510\n",
      "Iteration :  0\n",
      "Loss :  -2416.750119795705\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  511\n",
      "Iteration :  0\n",
      "Loss :  -2416.4022962242807\n",
      "**********************************************\n",
      "Epoch :  512\n",
      "Iteration :  0\n",
      "Loss :  -2413.6785865083275\n",
      "**********************************************\n",
      "Epoch :  513\n",
      "Iteration :  0\n",
      "Loss :  -2409.058113185747\n",
      "**********************************************\n",
      "Epoch :  514\n",
      "Iteration :  0\n",
      "Loss :  -2409.420694530483\n",
      "**********************************************\n",
      "Epoch :  515\n",
      "Iteration :  0\n",
      "Loss :  -2409.9350655712824\n",
      "**********************************************\n",
      "Epoch :  516\n",
      "Iteration :  0\n",
      "Loss :  -2415.2019276710603\n",
      "**********************************************\n",
      "Epoch :  517\n",
      "Iteration :  0\n",
      "Loss :  -2415.776394507953\n",
      "**********************************************\n",
      "Epoch :  518\n",
      "Iteration :  0\n",
      "Loss :  -2413.563064428936\n",
      "**********************************************\n",
      "Epoch :  519\n",
      "Iteration :  0\n",
      "Loss :  -2410.493157958232\n",
      "**********************************************\n",
      "Epoch :  520\n",
      "Iteration :  0\n",
      "Loss :  -2405.129609585847\n",
      "**********************************************\n",
      "Epoch :  521\n",
      "Iteration :  0\n",
      "Loss :  -2412.1438009869826\n",
      "**********************************************\n",
      "Epoch :  522\n",
      "Iteration :  0\n",
      "Loss :  -2416.6943639326587\n",
      "**********************************************\n",
      "Epoch :  523\n",
      "Iteration :  0\n",
      "Loss :  -2415.893266014633\n",
      "**********************************************\n",
      "Epoch :  524\n",
      "Iteration :  0\n",
      "Loss :  -2411.967629805707\n",
      "**********************************************\n",
      "Epoch :  525\n",
      "Iteration :  0\n",
      "Loss :  -2406.8521529662994\n",
      "**********************************************\n",
      "Epoch :  526\n",
      "Iteration :  0\n",
      "Loss :  -2410.8635285103855\n",
      "**********************************************\n",
      "Epoch :  527\n",
      "Iteration :  0\n",
      "Loss :  -2414.241271422632\n",
      "**********************************************\n",
      "Epoch :  528\n",
      "Iteration :  0\n",
      "Loss :  -2417.102330506479\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  529\n",
      "Iteration :  0\n",
      "Loss :  -2415.417101255081\n",
      "**********************************************\n",
      "Epoch :  530\n",
      "Iteration :  0\n",
      "Loss :  -2411.2765604311853\n",
      "**********************************************\n",
      "Epoch :  531\n",
      "Iteration :  0\n",
      "Loss :  -2409.1907961030993\n",
      "**********************************************\n",
      "Epoch :  532\n",
      "Iteration :  0\n",
      "Loss :  -2406.0632580019937\n",
      "**********************************************\n",
      "Epoch :  533\n",
      "Iteration :  0\n",
      "Loss :  -2413.317376725788\n",
      "**********************************************\n",
      "Epoch :  534\n",
      "Iteration :  0\n",
      "Loss :  -2416.3562575634487\n",
      "**********************************************\n",
      "Epoch :  535\n",
      "Iteration :  0\n",
      "Loss :  -2412.9119740935325\n",
      "**********************************************\n",
      "Epoch :  536\n",
      "Iteration :  0\n",
      "Loss :  -2408.371280435858\n",
      "**********************************************\n",
      "Epoch :  537\n",
      "Iteration :  0\n",
      "Loss :  -2404.418972590146\n",
      "**********************************************\n",
      "Epoch :  538\n",
      "Iteration :  0\n",
      "Loss :  -2414.5187234796854\n",
      "**********************************************\n",
      "Epoch :  539\n",
      "Iteration :  0\n",
      "Loss :  -2417.0096474980023\n",
      "**********************************************\n",
      "Epoch :  540\n",
      "Iteration :  0\n",
      "Loss :  -2412.001499927992\n",
      "**********************************************\n",
      "Epoch :  541\n",
      "Iteration :  0\n",
      "Loss :  -2409.731628890784\n",
      "**********************************************\n",
      "Epoch :  542\n",
      "Iteration :  0\n",
      "Loss :  -2407.6065365336817\n",
      "**********************************************\n",
      "Epoch :  543\n",
      "Iteration :  0\n",
      "Loss :  -2414.0693129567903\n",
      "**********************************************\n",
      "Epoch :  544\n",
      "Iteration :  0\n",
      "Loss :  -2416.514358988046\n",
      "**********************************************\n",
      "Epoch :  545\n",
      "Iteration :  0\n",
      "Loss :  -2414.762942732438\n",
      "**********************************************\n",
      "Epoch :  546\n",
      "Iteration :  0\n",
      "Loss :  -2411.7789195764244\n",
      "**********************************************\n",
      "Epoch :  547\n",
      "Iteration :  0\n",
      "Loss :  -2407.9678803403294\n",
      "**********************************************\n",
      "Epoch :  548\n",
      "Iteration :  0\n",
      "Loss :  -2412.204973270109\n",
      "**********************************************\n",
      "Epoch :  549\n",
      "Iteration :  0\n",
      "Loss :  -2415.4227990322447\n",
      "**********************************************\n",
      "Epoch :  550\n",
      "Iteration :  0\n",
      "Loss :  -2417.332870801792\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :  0\n",
      "Loss :  -2415.867384644579\n",
      "**********************************************\n",
      "Epoch :  552\n",
      "Iteration :  0\n",
      "Loss :  -2411.6983652789063\n",
      "**********************************************\n",
      "Epoch :  553\n",
      "Iteration :  0\n",
      "Loss :  -2410.4715646656286\n",
      "**********************************************\n",
      "Epoch :  554\n",
      "Iteration :  0\n",
      "Loss :  -2409.720449098141\n",
      "**********************************************\n",
      "Epoch :  555\n",
      "Iteration :  0\n",
      "Loss :  -2415.3597780276464\n",
      "**********************************************\n",
      "Epoch :  556\n",
      "Iteration :  0\n",
      "Loss :  -2417.2544175562407\n",
      "**********************************************\n",
      "Epoch :  557\n",
      "Iteration :  0\n",
      "Loss :  -2416.186536913909\n",
      "**********************************************\n",
      "Epoch :  558\n",
      "Iteration :  0\n",
      "Loss :  -2413.7314916436885\n",
      "**********************************************\n",
      "Epoch :  559\n",
      "Iteration :  0\n",
      "Loss :  -2409.0292357352\n",
      "**********************************************\n",
      "Epoch :  560\n",
      "Iteration :  0\n",
      "Loss :  -2410.3224362379924\n",
      "**********************************************\n",
      "Epoch :  561\n",
      "Iteration :  0\n",
      "Loss :  -2411.7524977594953\n",
      "**********************************************\n",
      "Epoch :  562\n",
      "Iteration :  0\n",
      "Loss :  -2416.3139851995606\n",
      "**********************************************\n",
      "Epoch :  563\n",
      "Iteration :  0\n",
      "Loss :  -2417.2646054633638\n",
      "**********************************************\n",
      "Epoch :  564\n",
      "Iteration :  0\n",
      "Loss :  -2414.7706665568717\n",
      "**********************************************\n",
      "Epoch :  565\n",
      "Iteration :  0\n",
      "Loss :  -2411.355313843689\n",
      "**********************************************\n",
      "Epoch :  566\n",
      "Iteration :  0\n",
      "Loss :  -2406.231571382663\n",
      "**********************************************\n",
      "Epoch :  567\n",
      "Iteration :  0\n",
      "Loss :  -2411.751499719933\n",
      "**********************************************\n",
      "Epoch :  568\n",
      "Iteration :  0\n",
      "Loss :  -2415.9492953876825\n",
      "**********************************************\n",
      "Epoch :  569\n",
      "Iteration :  0\n",
      "Loss :  -2416.7786995155584\n",
      "**********************************************\n",
      "Epoch :  570\n",
      "Iteration :  0\n",
      "Loss :  -2414.1914326122574\n",
      "**********************************************\n",
      "Epoch :  571\n",
      "Iteration :  0\n",
      "Loss :  -2409.8504485528993\n",
      "**********************************************\n",
      "Epoch :  572\n",
      "Iteration :  0\n",
      "Loss :  -2409.2329628791604\n",
      "**********************************************\n",
      "Epoch :  573\n",
      "Iteration :  0\n",
      "Loss :  -2408.1841626820096\n",
      "**********************************************\n",
      "Epoch :  574\n",
      "Iteration :  0\n",
      "Loss :  -2415.258978199811\n",
      "**********************************************\n",
      "Epoch :  575\n",
      "Iteration :  0\n",
      "Loss :  -2416.726940864112\n",
      "**********************************************\n",
      "Epoch :  576\n",
      "Iteration :  0\n",
      "Loss :  -2411.7933094118766\n",
      "**********************************************\n",
      "Epoch :  577\n",
      "Iteration :  0\n",
      "Loss :  -2408.7615090108607\n",
      "**********************************************\n",
      "Epoch :  578\n",
      "Iteration :  0\n",
      "Loss :  -2406.619273259142\n",
      "**********************************************\n",
      "Epoch :  579\n",
      "Iteration :  0\n",
      "Loss :  -2414.614067857935\n",
      "**********************************************\n",
      "Epoch :  580\n",
      "Iteration :  0\n",
      "Loss :  -2415.9909821011215\n",
      "**********************************************\n",
      "Epoch :  581\n",
      "Iteration :  0\n",
      "Loss :  -2413.197462109864\n",
      "**********************************************\n",
      "Epoch :  582\n",
      "Iteration :  0\n",
      "Loss :  -2410.7312533570553\n",
      "**********************************************\n",
      "Epoch :  583\n",
      "Iteration :  0\n",
      "Loss :  -2406.4520305941583\n",
      "**********************************************\n",
      "Epoch :  584\n",
      "Iteration :  0\n",
      "Loss :  -2412.2194254934498\n",
      "**********************************************\n",
      "Epoch :  585\n",
      "Iteration :  0\n",
      "Loss :  -2416.1171932511047\n",
      "**********************************************\n",
      "Epoch :  586\n",
      "Iteration :  0\n",
      "Loss :  -2415.4962951744283\n",
      "**********************************************\n",
      "Epoch :  587\n",
      "Iteration :  0\n",
      "Loss :  -2412.1275620086853\n",
      "**********************************************\n",
      "Epoch :  588\n",
      "Iteration :  0\n",
      "Loss :  -2407.252197060344\n",
      "**********************************************\n",
      "Epoch :  589\n",
      "Iteration :  0\n",
      "Loss :  -2410.3123026972453\n",
      "**********************************************\n",
      "Epoch :  590\n",
      "Iteration :  0\n",
      "Loss :  -2413.661520373337\n",
      "**********************************************\n",
      "Epoch :  591\n",
      "Iteration :  0\n",
      "Loss :  -2417.2507882882223\n",
      "**********************************************\n",
      "Epoch :  592\n",
      "Iteration :  0\n",
      "Loss :  -2415.8956342220795\n",
      "**********************************************\n",
      "Epoch :  593\n",
      "Iteration :  0\n",
      "Loss :  -2412.8904550543753\n",
      "**********************************************\n",
      "Epoch :  594\n",
      "Iteration :  0\n",
      "Loss :  -2411.161387451931\n",
      "**********************************************\n",
      "Epoch :  595\n",
      "Iteration :  0\n",
      "Loss :  -2406.649408081849\n",
      "**********************************************\n",
      "Epoch :  596\n",
      "Iteration :  0\n",
      "Loss :  -2410.772969403493\n",
      "**********************************************\n",
      "Epoch :  597\n",
      "Iteration :  0\n",
      "Loss :  -2416.0034805041946\n",
      "**********************************************\n",
      "Epoch :  598\n",
      "Iteration :  0\n",
      "Loss :  -2417.157144884919\n",
      "**********************************************\n",
      "Epoch :  599\n",
      "Iteration :  0\n",
      "Loss :  -2413.242730231335\n",
      "**********************************************\n",
      "Epoch :  600\n",
      "Iteration :  0\n",
      "Loss :  -2408.542627475615\n",
      "**********************************************\n",
      "Epoch :  601\n",
      "Iteration :  0\n",
      "Loss :  -2409.527549959866\n",
      "**********************************************\n",
      "Epoch :  602\n",
      "Iteration :  0\n",
      "Loss :  -2408.9802575361737\n",
      "**********************************************\n",
      "Epoch :  603\n",
      "Iteration :  0\n",
      "Loss :  -2413.7272736183963\n",
      "**********************************************\n",
      "Epoch :  604\n",
      "Iteration :  0\n",
      "Loss :  -2416.7728750862616\n",
      "**********************************************\n",
      "Epoch :  605\n",
      "Iteration :  0\n",
      "Loss :  -2415.1700357089326\n",
      "**********************************************\n",
      "Epoch :  606\n",
      "Iteration :  0\n",
      "Loss :  -2411.0078655656953\n",
      "**********************************************\n",
      "Epoch :  607\n",
      "Iteration :  0\n",
      "Loss :  -2405.344836782866\n",
      "**********************************************\n",
      "Epoch :  608\n",
      "Iteration :  0\n",
      "Loss :  -2408.713461778078\n",
      "**********************************************\n",
      "Epoch :  609\n",
      "Iteration :  0\n",
      "Loss :  -2413.258205334574\n",
      "**********************************************\n",
      "Epoch :  610\n",
      "Iteration :  0\n",
      "Loss :  -2417.2349666056116\n",
      "**********************************************\n",
      "Epoch :  611\n",
      "Iteration :  0\n",
      "Loss :  -2414.711998167456\n",
      "**********************************************\n",
      "Epoch :  612\n",
      "Iteration :  0\n",
      "Loss :  -2409.5843813235165\n",
      "**********************************************\n",
      "Epoch :  613\n",
      "Iteration :  0\n",
      "Loss :  -2408.892201642373\n",
      "**********************************************\n",
      "Epoch :  614\n",
      "Iteration :  0\n",
      "Loss :  -2406.9775509069646\n",
      "**********************************************\n",
      "Epoch :  615\n",
      "Iteration :  0\n",
      "Loss :  -2412.8995253843777\n",
      "**********************************************\n",
      "Epoch :  616\n",
      "Iteration :  0\n",
      "Loss :  -2415.921185868339\n",
      "**********************************************\n",
      "Epoch :  617\n",
      "Iteration :  0\n",
      "Loss :  -2412.9010800775773\n",
      "**********************************************\n",
      "Epoch :  618\n",
      "Iteration :  0\n",
      "Loss :  -2408.103999303221\n",
      "**********************************************\n",
      "Epoch :  619\n",
      "Iteration :  0\n",
      "Loss :  -2405.426718508202\n",
      "**********************************************\n",
      "Epoch :  620\n",
      "Iteration :  0\n",
      "Loss :  -2414.549234795161\n",
      "**********************************************\n",
      "Epoch :  621\n",
      "Iteration :  0\n",
      "Loss :  -2416.7758038342945\n",
      "**********************************************\n",
      "Epoch :  622\n",
      "Iteration :  0\n",
      "Loss :  -2414.355498486679\n",
      "**********************************************\n",
      "Epoch :  623\n",
      "Iteration :  0\n",
      "Loss :  -2412.0878766473743\n",
      "**********************************************\n",
      "Epoch :  624\n",
      "Iteration :  0\n",
      "Loss :  -2407.413406334501\n",
      "**********************************************\n",
      "Epoch :  625\n",
      "Iteration :  0\n",
      "Loss :  -2410.907031559683\n",
      "**********************************************\n",
      "Epoch :  626\n",
      "Iteration :  0\n",
      "Loss :  -2415.1665936300847\n",
      "**********************************************\n",
      "Epoch :  627\n",
      "Iteration :  0\n",
      "Loss :  -2417.474386937631\n",
      "Saving new model!\n",
      "**********************************************\n",
      "Epoch :  628\n",
      "Iteration :  0\n",
      "Loss :  -2415.661674243951\n",
      "**********************************************\n",
      "Epoch :  629\n",
      "Iteration :  0\n",
      "Loss :  -2411.832661979704\n",
      "**********************************************\n",
      "Epoch :  630\n",
      "Iteration :  0\n",
      "Loss :  -2410.04871625427\n",
      "**********************************************\n",
      "Epoch :  631\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml3d2\\lib\\shutil.py:823\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 17] The system cannot move the file to a different disk drive: 'C:\\\\Users\\\\mreen\\\\AppData\\\\Local\\\\Temp\\\\tmplekllsutwandb-media\\\\t5tg5im9.pts.json' -> 'D:\\\\Projects\\\\ML3D\\\\Final Project\\\\ssl_3d_recon_pytorch\\\\wandb\\\\run-20220721_205719-h50igo5c\\\\files\\\\media\\\\object3D\\\\point_cloud_1_3787_ead99be8fdb25ca14a95.pts.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_full\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Projects\\ML3D\\Final Project\\ssl_3d_recon_pytorch\\src\\training\\train_full.py:279\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    275\u001b[0m   recon_net \u001b[38;5;241m=\u001b[39m ReconstructionNet()\n\u001b[0;32m    276\u001b[0m   pose_net \u001b[38;5;241m=\u001b[39m PoseNet() \u001b[38;5;66;03m## Need to merge\u001b[39;00m\n\u001b[1;32m--> 279\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecon_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpose_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Projects\\ML3D\\Final Project\\ssl_3d_recon_pytorch\\src\\training\\train_full.py:153\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(recon_net, pose_net, device, config, trainloader, valloader)\u001b[0m\n\u001b[0;32m    150\u001b[0m log_list \u001b[38;5;241m=\u001b[39m [images,masks]\n\u001b[0;32m    151\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m: log_list})\n\u001b[1;32m--> 153\u001b[0m wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoint_cloud_1\u001b[39m\u001b[38;5;124m\"\u001b[39m : [wandb\u001b[38;5;241m.\u001b[39mObject3D(temp_pcl_xyz),wandb\u001b[38;5;241m.\u001b[39mObject3D(temp_pcl_rgb)]})\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# print(img_out[1][0].shape)\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# Reconstruct the point cloud from and predict the pose of projected images\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_proj\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;66;03m# print(idx)\u001b[39;00m\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# print('Pojected images : ', img_out[idx].shape)\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# print(torch.permute(img_out[idx][0],[0, 3, 1, 2]).shape)\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# temp_img = torch.permute(img_out[0][idx],[0, 3, 1, 2]).contiguous()\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml3d2\\lib\\site-packages\\wandb\\sdk\\wandb_run.py:256\u001b[0m, in \u001b[0;36m_run_decorator._noop.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m         wandb\u001b[38;5;241m.\u001b[39mtermwarn(message, repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mDummy()\n\u001b[1;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml3d2\\lib\\site-packages\\wandb\\sdk\\wandb_run.py:222\u001b[0m, in \u001b[0;36m_run_decorator._attach.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_is_attaching \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml3d2\\lib\\site-packages\\wandb\\sdk\\wandb_run.py:1543\u001b[0m, in \u001b[0;36mRun.log\u001b[1;34m(self, data, step, commit, sync)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sync \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1537\u001b[0m     deprecate\u001b[38;5;241m.\u001b[39mdeprecate(\n\u001b[0;32m   1538\u001b[0m         field_name\u001b[38;5;241m=\u001b[39mdeprecate\u001b[38;5;241m.\u001b[39mDeprecated\u001b[38;5;241m.\u001b[39mrun__log_sync,\n\u001b[0;32m   1539\u001b[0m         warning_message\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1540\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sync` argument is deprecated and does not affect the behaviour of `wandb.log`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1541\u001b[0m         ),\n\u001b[0;32m   1542\u001b[0m     )\n\u001b[1;32m-> 1543\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml3d2\\lib\\site-packages\\wandb\\sdk\\wandb_run.py:1334\u001b[0m, in \u001b[0;36mRun._log\u001b[1;34m(self, data, step, commit)\u001b[0m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey values passed to `wandb.log` must be strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1334\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partial_history_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1337\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetpid() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_pid \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_attached:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml3d2\\lib\\site-packages\\wandb\\sdk\\wandb_run.py:1223\u001b[0m, in \u001b[0;36mRun._partial_history_callback\u001b[1;34m(self, row, step, commit)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39minterface:\n\u001b[0;32m   1221\u001b[0m     not_using_tensorboard \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(wandb\u001b[38;5;241m.\u001b[39mpatched[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1223\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_partial_history\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflush\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpublish_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnot_using_tensorboard\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml3d2\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py:541\u001b[0m, in \u001b[0;36mInterfaceBase.publish_partial_history\u001b[1;34m(self, data, user_step, step, flush, publish_step, run)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_partial_history\u001b[39m(\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    532\u001b[0m     data: \u001b[38;5;28mdict\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    537\u001b[0m     run: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    538\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    539\u001b[0m     run \u001b[38;5;241m=\u001b[39m run \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run\n\u001b[1;32m--> 541\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mhistory_dict_to_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_copy_err\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    542\u001b[0m     data\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    544\u001b[0m     partial_history \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPartialHistoryRequest()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml3d2\\lib\\site-packages\\wandb\\sdk\\data_types\\utils.py:54\u001b[0m, in \u001b[0;36mhistory_dict_to_json\u001b[1;34m(run, payload, step, ignore_copy_err)\u001b[0m\n\u001b[0;32m     50\u001b[0m         payload[key] \u001b[38;5;241m=\u001b[39m history_dict_to_json(\n\u001b[0;32m     51\u001b[0m             run, val, step\u001b[38;5;241m=\u001b[39mstep, ignore_copy_err\u001b[38;5;241m=\u001b[39mignore_copy_err\n\u001b[0;32m     52\u001b[0m         )\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m         payload[key] \u001b[38;5;241m=\u001b[39m \u001b[43mval_to_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_copy_err\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_copy_err\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m payload\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml3d2\\lib\\site-packages\\wandb\\sdk\\data_types\\utils.py:99\u001b[0m, in \u001b[0;36mval_to_json\u001b[1;34m(run, key, val, namespace, ignore_copy_err)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _server_accepts_image_filenames():\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m items:\n\u001b[1;32m---> 99\u001b[0m         \u001b[43mitem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_to_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m            \u001b[49m\u001b[43mignore_copy_err\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_copy_err\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(items):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml3d2\\lib\\site-packages\\wandb\\sdk\\data_types\\base_types\\media.py:132\u001b[0m, in \u001b[0;36mMedia.bind_to_run\u001b[1;34m(self, run, key, step, id_, ignore_copy_err)\u001b[0m\n\u001b[0;32m    129\u001b[0m util\u001b[38;5;241m.\u001b[39mmkdir_exists_ok(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(new_path))\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_tmp:\n\u001b[1;32m--> 132\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m new_path\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_tmp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml3d2\\lib\\shutil.py:843\u001b[0m, in \u001b[0;36mmove\u001b[1;34m(src, dst, copy_function)\u001b[0m\n\u001b[0;32m    841\u001b[0m         rmtree(src)\n\u001b[0;32m    842\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 843\u001b[0m         \u001b[43mcopy_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_dst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    844\u001b[0m         os\u001b[38;5;241m.\u001b[39munlink(src)\n\u001b[0;32m    845\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m real_dst\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml3d2\\lib\\shutil.py:444\u001b[0m, in \u001b[0;36mcopy2\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[0;32m    443\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[1;32m--> 444\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m copystat(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[0;32m    446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml3d2\\lib\\shutil.py:284\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;66;03m# Windows, see:\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;66;03m# https://github.com/python/cpython/pull/7160#discussion_r195405230\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _WINDOWS \u001b[38;5;129;01mand\u001b[39;00m file_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 284\u001b[0m     \u001b[43m_copyfileobj_readinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfsrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCOPY_BUFSIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dst\n\u001b[0;32m    287\u001b[0m copyfileobj(fsrc, fdst)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ml3d2\\lib\\shutil.py:195\u001b[0m, in \u001b[0;36m_copyfileobj_readinto\u001b[1;34m(fsrc, fdst, length)\u001b[0m\n\u001b[0;32m    193\u001b[0m         fdst\u001b[38;5;241m.\u001b[39mwrite(smv)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 195\u001b[0m     \u001b[43mfdst_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmv\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_full.main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "963f6dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PoseNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0d79511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             896\n",
      "              ReLU-2         [-1, 32, 112, 112]               0\n",
      "            Conv2d-3           [-1, 64, 56, 56]          18,496\n",
      "              ReLU-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5          [-1, 128, 28, 28]          73,856\n",
      "              ReLU-6          [-1, 128, 28, 28]               0\n",
      "            Conv2d-7          [-1, 256, 14, 14]         295,168\n",
      "              ReLU-8          [-1, 256, 14, 14]               0\n",
      "            Linear-9                  [-1, 128]       6,422,656\n",
      "             ReLU-10                  [-1, 128]               0\n",
      "           Linear-11                  [-1, 128]          16,512\n",
      "             ReLU-12                  [-1, 128]               0\n",
      "           Linear-13                  [-1, 128]          16,512\n",
      "             ReLU-14                  [-1, 128]               0\n",
      "           Linear-15                    [-1, 2]             258\n",
      "             Tanh-16                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 6,844,354\n",
      "Trainable params: 6,844,354\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 11.49\n",
      "Params size (MB): 26.11\n",
      "Estimated Total Size (MB): 38.17\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(summary(model,(3,224,224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e27c9a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = torch.rand(3,224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c24e901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.forward(torch.unsqueeze(test_input,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9e22e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99aa934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36c9017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_loss = PoseLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16aa2cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1492, 0.2448]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe0dee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.rand(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f3d0abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = pose_loss(output,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0dc8b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5801, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c07ee10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf37ffd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5801, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb62fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4340c082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d2c7ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  1  \tLoss :  0.8586193323135376\n",
      "Epoch :  2  \tLoss :  0.8138160109519958\n",
      "Epoch :  3  \tLoss :  0.7770995497703552\n",
      "Epoch :  4  \tLoss :  0.7276517152786255\n",
      "Epoch :  5  \tLoss :  0.6648929119110107\n",
      "Epoch :  6  \tLoss :  0.5850026607513428\n",
      "Epoch :  7  \tLoss :  0.4852640926837921\n",
      "Epoch :  8  \tLoss :  0.36141180992126465\n",
      "Epoch :  9  \tLoss :  0.2011251449584961\n",
      "Epoch :  10  \tLoss :  0.10019803047180176\n",
      "Epoch :  11  \tLoss :  0.16607031226158142\n",
      "Epoch :  12  \tLoss :  0.20956993103027344\n",
      "Epoch :  13  \tLoss :  0.17526426911354065\n",
      "Epoch :  14  \tLoss :  0.09566956758499146\n",
      "Epoch :  15  \tLoss :  0.04290801286697388\n",
      "Epoch :  16  \tLoss :  0.0923575609922409\n",
      "Epoch :  17  \tLoss :  0.1261928528547287\n",
      "Epoch :  18  \tLoss :  0.12607254087924957\n",
      "Epoch :  19  \tLoss :  0.09795515239238739\n",
      "Epoch :  20  \tLoss :  0.04615378379821777\n",
      "Epoch :  21  \tLoss :  0.031188935041427612\n",
      "Epoch :  22  \tLoss :  0.06748118996620178\n",
      "Epoch :  23  \tLoss :  0.066855788230896\n",
      "Epoch :  24  \tLoss :  0.03574046492576599\n",
      "Epoch :  25  \tLoss :  0.018218427896499634\n",
      "Epoch :  26  \tLoss :  0.03889918327331543\n",
      "Epoch :  27  \tLoss :  0.03303515911102295\n",
      "Epoch :  28  \tLoss :  0.003627270460128784\n",
      "Epoch :  29  \tLoss :  0.04850524663925171\n",
      "Epoch :  30  \tLoss :  0.06935334205627441\n",
      "Epoch :  31  \tLoss :  0.06119218468666077\n",
      "Epoch :  32  \tLoss :  0.02840372920036316\n",
      "Epoch :  33  \tLoss :  0.023521602153778076\n",
      "Epoch :  34  \tLoss :  0.046417951583862305\n",
      "Epoch :  35  \tLoss :  0.04564619064331055\n",
      "Epoch :  36  \tLoss :  0.02394115924835205\n",
      "Epoch :  37  \tLoss :  0.017796814441680908\n",
      "Epoch :  38  \tLoss :  0.03295999765396118\n",
      "Epoch :  39  \tLoss :  0.023421823978424072\n",
      "Epoch :  40  \tLoss :  0.007290571928024292\n",
      "Epoch :  41  \tLoss :  0.01303139328956604\n",
      "Epoch :  42  \tLoss :  0.003293156623840332\n",
      "Epoch :  43  \tLoss :  0.01789608597755432\n",
      "Epoch :  44  \tLoss :  0.022712379693984985\n",
      "Epoch :  45  \tLoss :  0.019956111907958984\n",
      "Epoch :  46  \tLoss :  0.0072203874588012695\n",
      "Epoch :  47  \tLoss :  0.007121354341506958\n",
      "Epoch :  48  \tLoss :  0.019766658544540405\n",
      "Epoch :  49  \tLoss :  0.009391963481903076\n",
      "Epoch :  50  \tLoss :  0.02112630009651184\n",
      "Epoch :  51  \tLoss :  0.027636289596557617\n",
      "Epoch :  52  \tLoss :  0.013218611478805542\n",
      "Epoch :  53  \tLoss :  0.020901590585708618\n",
      "Epoch :  54  \tLoss :  0.030199289321899414\n",
      "Epoch :  55  \tLoss :  0.01661890745162964\n",
      "Epoch :  56  \tLoss :  0.01644265651702881\n",
      "Epoch :  57  \tLoss :  0.025474071502685547\n",
      "Epoch :  58  \tLoss :  0.013700991868972778\n",
      "Epoch :  59  \tLoss :  0.017492949962615967\n",
      "Epoch :  60  \tLoss :  0.02466869354248047\n",
      "Epoch :  61  \tLoss :  0.00981515645980835\n",
      "Epoch :  62  \tLoss :  0.023723334074020386\n",
      "Epoch :  63  \tLoss :  0.03379368782043457\n",
      "Epoch :  64  \tLoss :  0.02359592914581299\n",
      "Epoch :  65  \tLoss :  0.005441635847091675\n",
      "Epoch :  66  \tLoss :  0.011415541172027588\n",
      "Epoch :  67  \tLoss :  0.003714919090270996\n",
      "Epoch :  68  \tLoss :  0.0028268396854400635\n",
      "Epoch :  69  \tLoss :  0.011400341987609863\n",
      "Epoch :  70  \tLoss :  0.004410892724990845\n",
      "Epoch :  71  \tLoss :  0.02207455039024353\n",
      "Epoch :  72  \tLoss :  0.025359153747558594\n",
      "Epoch :  73  \tLoss :  0.007594019174575806\n",
      "Epoch :  74  \tLoss :  0.027853578329086304\n",
      "Epoch :  75  \tLoss :  0.04022324085235596\n",
      "Epoch :  76  \tLoss :  0.032797038555145264\n",
      "Epoch :  77  \tLoss :  0.007122337818145752\n",
      "Epoch :  78  \tLoss :  0.03658053278923035\n",
      "Epoch :  79  \tLoss :  0.055681586265563965\n",
      "Epoch :  80  \tLoss :  0.0512947142124176\n",
      "Epoch :  81  \tLoss :  0.026181906461715698\n",
      "Epoch :  82  \tLoss :  0.0158272385597229\n",
      "Epoch :  83  \tLoss :  0.033726006746292114\n",
      "Epoch :  84  \tLoss :  0.03133702278137207\n",
      "Epoch :  85  \tLoss :  0.010615110397338867\n",
      "Epoch :  86  \tLoss :  0.027869373559951782\n",
      "Epoch :  87  \tLoss :  0.042766571044921875\n",
      "Epoch :  88  \tLoss :  0.0354345440864563\n",
      "Epoch :  89  \tLoss :  0.008688122034072876\n",
      "Epoch :  90  \tLoss :  0.033743977546691895\n",
      "Epoch :  91  \tLoss :  0.05291926860809326\n",
      "Epoch :  92  \tLoss :  0.05262365937232971\n",
      "Epoch :  93  \tLoss :  0.03486979007720947\n",
      "Epoch :  94  \tLoss :  0.000344693660736084\n",
      "Epoch :  95  \tLoss :  0.05134063959121704\n",
      "Epoch :  96  \tLoss :  0.07831206917762756\n",
      "Epoch :  97  \tLoss :  0.08111634850502014\n",
      "Epoch :  98  \tLoss :  0.06207874417304993\n",
      "Epoch :  99  \tLoss :  0.024775713682174683\n",
      "Epoch :  100  \tLoss :  0.026556849479675293\n"
     ]
    }
   ],
   "source": [
    "model = PoseNet()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001 )\n",
    "model.train()\n",
    "loss_criterion = PoseLoss()\n",
    "loss_log = []\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model.forward(torch.unsqueeze(test_input,0))\n",
    "    # print(\"prediction shape: \", prediction.shape)\n",
    "    loss_total = loss_criterion(prediction,target)\n",
    "    loss_total.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    loss_log.append(loss_total.item())\n",
    "    print(\"Epoch : \", i+1, \" \\tLoss : \", loss_total.item() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a5f878",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml3d2] *",
   "language": "python",
   "name": "conda-env-ml3d2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
